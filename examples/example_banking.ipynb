{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "## Exploring the banking dataset using AutoLabel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80110a5b-2b3e-45e2-a2da-f6fa00200dff",
   "metadata": {},
   "source": [
    "#### Setup the API Keys for providers that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92993c83-4473-4e05-9510-f543b070c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=***REMOVED***\n",
      "env: ANTHROPIC_API_KEY=***REMOVED***\n"
     ]
    }
   ],
   "source": [
    "# %env OPENAI_API_KEY=***REMOVED***\n",
    "%env OPENAI_API_KEY=***REMOVED***\n",
    "%env ANTHROPIC_API_KEY=***REMOVED***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc861154-fcec-435b-b0ef-26fe7e695a3b",
   "metadata": {},
   "source": [
    "### Get the correct data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7de483b1-f984-44cc-81e2-68bcd07009c6",
   "metadata": {},
   "source": [
    "First lets make sure that we download the correct data. Currently data has been hosted on s3 but we will upload it to huggingface data as well in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50c0274-789f-4849-8c0d-cc342c35fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://refuel-benchmarking/banking_seed.csv to data/banking_seed.csv\n",
      "download: s3://refuel-benchmarking/conll2003_seed.csv to data/conll2003_seed.csv\n",
      "download: s3://refuel-benchmarking/emotion_seed.csv to data/emotion_seed.csv\n",
      "download: s3://refuel-benchmarking/banking_test.csv to data/banking_test.csv\n",
      "download: s3://refuel-benchmarking/civil_comments_seed.csv to data/civil_comments_seed.csv\n",
      "download: s3://refuel-benchmarking/company_seed.csv to data/company_seed.csv\n",
      "download: s3://refuel-benchmarking/emotion_test.csv to data/emotion_test.csv\n",
      "download: s3://refuel-benchmarking/ledgar_seed.csv to data/ledgar_seed.csv\n",
      "download: s3://refuel-benchmarking/conll2003_test.csv to data/conll2003_test.csv\n",
      "download: s3://refuel-benchmarking/civil_comments_test.csv to data/civil_comments_test.csv\n",
      "download: s3://refuel-benchmarking/medqa_seed.csv to data/medqa_seed.csv\n",
      "download: s3://refuel-benchmarking/pubmed_qa_seed.csv to data/pubmed_qa_seed.csv\n",
      "download: s3://refuel-benchmarking/sciq_seed.csv to data/sciq_seed.csv\n",
      "download: s3://refuel-benchmarking/sciq_test.csv to data/sciq_test.csv\n",
      "download: s3://refuel-benchmarking/walmart_amazon_seed.csv to data/walmart_amazon_seed.csv\n",
      "download: s3://refuel-benchmarking/wikiann_seed.csv to data/wikiann_seed.csv\n",
      "download: s3://refuel-benchmarking/squad_v2_seed.csv to data/squad_v2_seed.csv\n",
      "download: s3://refuel-benchmarking/medqa_test.csv to data/medqa_test.csv\n",
      "download: s3://refuel-benchmarking/pubmed_qa_test.csv to data/pubmed_qa_test.csv\n",
      "download: s3://refuel-benchmarking/ledgar_test.csv to data/ledgar_test.csv\n",
      "download: s3://refuel-benchmarking/squad_v2_test.csv to data/squad_v2_test.csv\n",
      "download: s3://refuel-benchmarking/company_test.csv to data/company_test.csv\n",
      "download: s3://refuel-benchmarking/wikiann_test.csv to data/wikiann_test.csv\n",
      "download: s3://refuel-benchmarking/walmart_amazon_test.csv to data/walmart_amazon_test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://refuel-benchmarking data/ --recursive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c24be70-7b3a-42f5-856f-dbe068e7a25c",
   "metadata": {},
   "source": [
    "### Run the labeler after passing in my own seed examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "925d8a6c-a6b0-4b39-9320-c75119c58412",
   "metadata": {},
   "source": [
    "#### Create the config\n",
    "This config file has all the possible labels for the banking dataset. The model needs to choose one label from the label list provided. In input schema, we define the input columns that will be used by the oracle and the output column defines the label column, that is, the column that will be used as ground truth and will be tried to be generated by our library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f24ce0-d507-42ec-9e22-b03d4786424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_config = {\n",
    "    \"task_name\": \"BankingComplaintsClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at understanding bank customers support complaints and queries.\\nYour job is to correctly classify the provided input example into one of the following categories.\\nCategories:\\n{labels}\",\n",
    "        \"output_guidelines\": \"You will answer with just the the correct output label and nothing else.\",\n",
    "        \"labels\": [\n",
    "            \"activate_my_card\",\n",
    "            \"age_limit\",\n",
    "            \"apple_pay_or_google_pay\",\n",
    "            \"atm_support\",\n",
    "            \"automatic_top_up\",\n",
    "            \"balance_not_updated_after_bank_transfer\",\n",
    "            \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "            \"beneficiary_not_allowed\",\n",
    "            \"cancel_transfer\",\n",
    "            \"card_about_to_expire\",\n",
    "            \"card_acceptance\",\n",
    "            \"card_arrival\",\n",
    "            \"card_delivery_estimate\",\n",
    "            \"card_linking\",\n",
    "            \"card_not_working\",\n",
    "            \"card_payment_fee_charged\",\n",
    "            \"card_payment_not_recognised\",\n",
    "            \"card_payment_wrong_exchange_rate\",\n",
    "            \"card_swallowed\",\n",
    "            \"cash_withdrawal_charge\",\n",
    "            \"cash_withdrawal_not_recognised\",\n",
    "            \"change_pin\",\n",
    "            \"compromised_card\",\n",
    "            \"contactless_not_working\",\n",
    "            \"country_support\",\n",
    "            \"declined_card_payment\",\n",
    "            \"declined_cash_withdrawal\",\n",
    "            \"declined_transfer\",\n",
    "            \"direct_debit_payment_not_recognised\",\n",
    "            \"disposable_card_limits\",\n",
    "            \"edit_personal_details\",\n",
    "            \"exchange_charge\",\n",
    "            \"exchange_rate\",\n",
    "            \"exchange_via_app\",\n",
    "            \"extra_charge_on_statement\",\n",
    "            \"failed_transfer\",\n",
    "            \"fiat_currency_support\",\n",
    "            \"get_disposable_virtual_card\",\n",
    "            \"get_physical_card\",\n",
    "            \"getting_spare_card\",\n",
    "            \"getting_virtual_card\",\n",
    "            \"lost_or_stolen_card\",\n",
    "            \"lost_or_stolen_phone\",\n",
    "            \"order_physical_card\",\n",
    "            \"passcode_forgotten\",\n",
    "            \"pending_card_payment\",\n",
    "            \"pending_cash_withdrawal\",\n",
    "            \"pending_top_up\",\n",
    "            \"pending_transfer\",\n",
    "            \"pin_blocked\",\n",
    "            \"receiving_money\",\n",
    "            \"Refund_not_showing_up\",\n",
    "            \"request_refund\",\n",
    "            \"reverted_card_payment?\",\n",
    "            \"supported_cards_and_currencies\",\n",
    "            \"terminate_account\",\n",
    "            \"top_up_by_bank_transfer_charge\",\n",
    "            \"top_up_by_card_charge\",\n",
    "            \"top_up_by_cash_or_cheque\",\n",
    "            \"top_up_failed\",\n",
    "            \"top_up_limits\",\n",
    "            \"top_up_reverted\",\n",
    "            \"topping_up_by_card\",\n",
    "            \"transaction_charged_twice\",\n",
    "            \"transfer_fee_charged\",\n",
    "            \"transfer_into_account\",\n",
    "            \"transfer_not_received_by_recipient\",\n",
    "            \"transfer_timing\",\n",
    "            \"unable_to_verify_identity\",\n",
    "            \"verify_my_identity\",\n",
    "            \"verify_source_of_funds\",\n",
    "            \"verify_top_up\",\n",
    "            \"virtual_card_not_working\",\n",
    "            \"visa_or_mastercard\",\n",
    "            \"why_verify_identity\",\n",
    "            \"wrong_amount_of_cash_received\",\n",
    "            \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "        ],\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f693bdf-1814-4522-ad3e-d33f618c7b70",
   "metadata": {},
   "source": [
    "First dry run the model using the above specification and get an idea of the cost required to run the model \n",
    "\n",
    "Running it on just 100 examples to get an idea for the notebook, adjust the max_items as required and dont pass it if you need to run the oracle on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config=zero_shot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3adbe5058bc4bc68fbe6435a78b743b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.029\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.00292\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent.plan('../data/banking_test.csv', max_items=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2d4846d-d16b-40e9-b2cb-a0c579e260e4",
   "metadata": {},
   "source": [
    "Now, actually run the model and generate the list of labels for the banking dataset. You will get the computed metrics at the end of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5212c2808d240309011ae38871491cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:09:10 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25b4db0b913e95ba2361d8d599c9b3d6 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:09:10 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25b4db0b913e95ba2361d8d599c9b3d6 in your message.).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 0.04632399999999999\n",
      "Metric: support: [(50, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.68, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items = 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8973f5c-7aa2-443f-81f8-9046ed8c2046",
   "metadata": {},
   "source": [
    "## Change the prompt\n",
    "Analyze the dataframe generated above and make changes to the prompt in order to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1a4042-4aee-481f-ac77-b21d14925cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fixed_few_shot = {\n",
    "    \"task_name\": \"BankingComplaintsClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at understanding bank customers support complaints and queries.\\nYour job is to correctly classify the provided input example into one of the following categories.\\nCategories:\\n{labels}\",\n",
    "        \"output_guidelines\": \"You will answer with just the the correct output label and nothing else.\",\n",
    "        \"labels\": [\n",
    "            \"activate_my_card\",\n",
    "            \"age_limit\",\n",
    "            \"apple_pay_or_google_pay\",\n",
    "            \"atm_support\",\n",
    "            \"automatic_top_up\",\n",
    "            \"balance_not_updated_after_bank_transfer\",\n",
    "            \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "            \"beneficiary_not_allowed\",\n",
    "            \"cancel_transfer\",\n",
    "            \"card_about_to_expire\",\n",
    "            \"card_acceptance\",\n",
    "            \"card_arrival\",\n",
    "            \"card_delivery_estimate\",\n",
    "            \"card_linking\",\n",
    "            \"card_not_working\",\n",
    "            \"card_payment_fee_charged\",\n",
    "            \"card_payment_not_recognised\",\n",
    "            \"card_payment_wrong_exchange_rate\",\n",
    "            \"card_swallowed\",\n",
    "            \"cash_withdrawal_charge\",\n",
    "            \"cash_withdrawal_not_recognised\",\n",
    "            \"change_pin\",\n",
    "            \"compromised_card\",\n",
    "            \"contactless_not_working\",\n",
    "            \"country_support\",\n",
    "            \"declined_card_payment\",\n",
    "            \"declined_cash_withdrawal\",\n",
    "            \"declined_transfer\",\n",
    "            \"direct_debit_payment_not_recognised\",\n",
    "            \"disposable_card_limits\",\n",
    "            \"edit_personal_details\",\n",
    "            \"exchange_charge\",\n",
    "            \"exchange_rate\",\n",
    "            \"exchange_via_app\",\n",
    "            \"extra_charge_on_statement\",\n",
    "            \"failed_transfer\",\n",
    "            \"fiat_currency_support\",\n",
    "            \"get_disposable_virtual_card\",\n",
    "            \"get_physical_card\",\n",
    "            \"getting_spare_card\",\n",
    "            \"getting_virtual_card\",\n",
    "            \"lost_or_stolen_card\",\n",
    "            \"lost_or_stolen_phone\",\n",
    "            \"order_physical_card\",\n",
    "            \"passcode_forgotten\",\n",
    "            \"pending_card_payment\",\n",
    "            \"pending_cash_withdrawal\",\n",
    "            \"pending_top_up\",\n",
    "            \"pending_transfer\",\n",
    "            \"pin_blocked\",\n",
    "            \"receiving_money\",\n",
    "            \"Refund_not_showing_up\",\n",
    "            \"request_refund\",\n",
    "            \"reverted_card_payment?\",\n",
    "            \"supported_cards_and_currencies\",\n",
    "            \"terminate_account\",\n",
    "            \"top_up_by_bank_transfer_charge\",\n",
    "            \"top_up_by_card_charge\",\n",
    "            \"top_up_by_cash_or_cheque\",\n",
    "            \"top_up_failed\",\n",
    "            \"top_up_limits\",\n",
    "            \"top_up_reverted\",\n",
    "            \"topping_up_by_card\",\n",
    "            \"transaction_charged_twice\",\n",
    "            \"transfer_fee_charged\",\n",
    "            \"transfer_into_account\",\n",
    "            \"transfer_not_received_by_recipient\",\n",
    "            \"transfer_timing\",\n",
    "            \"unable_to_verify_identity\",\n",
    "            \"verify_my_identity\",\n",
    "            \"verify_source_of_funds\",\n",
    "            \"verify_top_up\",\n",
    "            \"virtual_card_not_working\",\n",
    "            \"visa_or_mastercard\",\n",
    "            \"why_verify_identity\",\n",
    "            \"wrong_amount_of_cash_received\",\n",
    "            \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "        ],\n",
    "        \"few_shot_examples\": [\n",
    "            {\n",
    "                \"example\": \"Is it free to transfer money or is there a fee?\",\n",
    "                \"label\": \"transfer_fee_charged\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"I need my PIN, where is it?\",\n",
    "                \"label\": \"get_physical_card\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"Can my salary be received and transferred to my current currency in my country?\",\n",
    "                \"label\": \"receiving_money\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"Why isn't my purchase exchange rate correct?\",\n",
    "                \"label\": \"card_payment_wrong_exchange_rate\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"Why was I charged a fee on a cash withdrawal?\",\n",
    "                \"label\": \"cash_withdrawal_charge\"\n",
    "            }\n",
    "        ],\n",
    "        \"few_shot_selection\": \"fixed\",\n",
    "        \"few_shot_num\": 5,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84eecfba-9859-4d6c-9f44-3755c71d3ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fbaae4df904a0193178f828809f7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $1.569\n",
      "Number of examples to label: 500\n",
      "Average cost per example: $0.00314\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: Is it free to transfer money or is there a fee?\n",
      "Output: transfer_fee_charged\n",
      "\n",
      "Input: I need my PIN, where is it?\n",
      "Output: get_physical_card\n",
      "\n",
      "Input: Can my salary be received and transferred to my current currency in my country?\n",
      "Output: receiving_money\n",
      "\n",
      "Input: Why isn't my purchase exchange rate correct?\n",
      "Output: card_payment_wrong_exchange_rate\n",
      "\n",
      "Input: Why was I charged a fee on a cash withdrawal?\n",
      "Output: cash_withdrawal_charge\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent = LabelingAgent(config_fixed_few_shot)\n",
    "agent.plan('../data/banking_test.csv', max_items = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a586b441-9e5c-459c-8c65-4f8294dac189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b2140de200431c874c00840a17ae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:13:55 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88375 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:13:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88375 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:00 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88442 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:00 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88442 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:04 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88472 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88472 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:06 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88448 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:06 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88448 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:08 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88614 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88614 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:12 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88816 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88816 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:14 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88838 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:14 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88838 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:16 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88741 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:16 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88741 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:19 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89143 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:19 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89143 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:21 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88833 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88833 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:23 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88997 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:23 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88997 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:26 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89049 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:26 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89049 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:27 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88439 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:27 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88439 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89218 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89218 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:32 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89151 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89151 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:34 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88931 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:34 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88931 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89208 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89208 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:38 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88475 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88475 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:40 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88534 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:40 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88534 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:43 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88743 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:43 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88743 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:45 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88798 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88798 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:48 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88496 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88496 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:50 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88671 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:50 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88671 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:53 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89036 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:53 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89036 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:55 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88906 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88906 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:57 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88820 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:57 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88820 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:14:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88913 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:14:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88913 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:02 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88689 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:02 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88689 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:04 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88744 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88744 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:06 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88558 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:06 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88558 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:09 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89021 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:09 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89021 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:11 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88364 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:11 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88364 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:15 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88765 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:15 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88765 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:19 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88458 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:19 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88458 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:21 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88652 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88652 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:24 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88521 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:24 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88521 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:26 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88593 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:26 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88593 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88515 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88515 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:33 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89155 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89155 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88674 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88674 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:38 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88437 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88437 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:40 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88400 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:40 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88400 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:43 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88842 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:43 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88842 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:46 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88420 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:46 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88420 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:48 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89045 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89045 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:49 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88687 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:49 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88687 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:52 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88813 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:52 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88813 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:54 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88843 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:54 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88843 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:57 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:57 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88982 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:15:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88640 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:15:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88640 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:01 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89256 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89256 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:05 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:05 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89448 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:13 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88598 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:13 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88598 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:29 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error generating from LLM: Rate limit reached for default-gpt-3.5-turbo in organization \n",
       "org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our \n",
       "help center at help.openai.com if you continue to have issues., returning empty result\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error generating from LLM: Rate limit reached for default-gpt-3.5-turbo in organization \n",
       "org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89546 / min. Contact us through our \n",
       "help center at help.openai.com if you continue to have issues., returning empty result\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:29.343 | ERROR    | autolabel.tasks.base:parse_llm_response:73 - Error parsing LLM response: \n",
      "2023-05-30 17:16:29.348 | ERROR    | autolabel.tasks.base:parse_llm_response:73 - Error parsing LLM response: \n",
      "2023-05-30 17:16:29.351 | ERROR    | autolabel.tasks.base:parse_llm_response:73 - Error parsing LLM response: \n",
      "2023-05-30 17:16:29.355 | ERROR    | autolabel.tasks.base:parse_llm_response:73 - Error parsing LLM response: \n",
      "2023-05-30 17:16:29.358 | ERROR    | autolabel.tasks.base:parse_llm_response:73 - Error parsing LLM response: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:29 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:29 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89372 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89043 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89043 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:32 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88428 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88428 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88555 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88555 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:16:44 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:16:44 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89008 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:17:39 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 61ff076e4ed9128c216f504b07ca156d in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:17:39 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 61ff076e4ed9128c216f504b07ca156d in your message.).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:18:05 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88800 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:18:05 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88800 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:18:07 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88718 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:18:07 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88718 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:18:39 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b896873741eef599482cfb51ccc4cbb9 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:18:39 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b896873741eef599482cfb51ccc4cbb9 in your message.).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:19:21 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2c9a9d74fbcff2407a903e0bd4bc47db in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:19:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2c9a9d74fbcff2407a903e0bd4bc47db in your message.).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:24 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89189 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:24 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89189 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:26 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88448 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:26 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88448 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:28 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89220 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:28 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89220 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88458 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88458 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:32 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88756 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88756 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:34 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88680 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:34 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88680 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88974 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88974 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:38 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88993 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88993 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:41 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88829 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:41 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88829 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:43 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88869 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:43 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88869 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:45 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89111 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89111 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:47 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89232 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89232 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:48 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88564 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88564 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:50 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88915 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:50 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88915 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:20:52 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89134 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:20:52 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89134 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 0.5308739999999998\n",
      "Metric: support: [(495, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.7353535353535353, 'index=0')]\n",
      "Metric: completion_rate: [(0.99, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a009109-e72b-4b69-9bc8-ea23af9a53e3",
   "metadata": {},
   "source": [
    "## Example selector\n",
    "Let's try to use an example selector. Let's use the big seed example set so that we can choose from a bigger set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517c7fa8-8926-42b5-b8d8-3aa73e5f64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_similarity_few_shot = {\n",
    "    \"task_name\": \"BankingComplaintsClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\"\n",
    "        # \"params\": {\"max_tokens\": 512},\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at understanding bank customers support complaints and queries.\\nYour job is to correctly classify the provided input example into one of the following categories.\\nCategories:\\n{labels}\",\n",
    "        \"output_guidelines\": \"You will answer with just the the correct output label and nothing else.\",\n",
    "        \"labels\": [\n",
    "            \"activate_my_card\",\n",
    "            \"age_limit\",\n",
    "            \"apple_pay_or_google_pay\",\n",
    "            \"atm_support\",\n",
    "            \"automatic_top_up\",\n",
    "            \"balance_not_updated_after_bank_transfer\",\n",
    "            \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "            \"beneficiary_not_allowed\",\n",
    "            \"cancel_transfer\",\n",
    "            \"card_about_to_expire\",\n",
    "            \"card_acceptance\",\n",
    "            \"card_arrival\",\n",
    "            \"card_delivery_estimate\",\n",
    "            \"card_linking\",\n",
    "            \"card_not_working\",\n",
    "            \"card_payment_fee_charged\",\n",
    "            \"card_payment_not_recognised\",\n",
    "            \"card_payment_wrong_exchange_rate\",\n",
    "            \"card_swallowed\",\n",
    "            \"cash_withdrawal_charge\",\n",
    "            \"cash_withdrawal_not_recognised\",\n",
    "            \"change_pin\",\n",
    "            \"compromised_card\",\n",
    "            \"contactless_not_working\",\n",
    "            \"country_support\",\n",
    "            \"declined_card_payment\",\n",
    "            \"declined_cash_withdrawal\",\n",
    "            \"declined_transfer\",\n",
    "            \"direct_debit_payment_not_recognised\",\n",
    "            \"disposable_card_limits\",\n",
    "            \"edit_personal_details\",\n",
    "            \"exchange_charge\",\n",
    "            \"exchange_rate\",\n",
    "            \"exchange_via_app\",\n",
    "            \"extra_charge_on_statement\",\n",
    "            \"failed_transfer\",\n",
    "            \"fiat_currency_support\",\n",
    "            \"get_disposable_virtual_card\",\n",
    "            \"get_physical_card\",\n",
    "            \"getting_spare_card\",\n",
    "            \"getting_virtual_card\",\n",
    "            \"lost_or_stolen_card\",\n",
    "            \"lost_or_stolen_phone\",\n",
    "            \"order_physical_card\",\n",
    "            \"passcode_forgotten\",\n",
    "            \"pending_card_payment\",\n",
    "            \"pending_cash_withdrawal\",\n",
    "            \"pending_top_up\",\n",
    "            \"pending_transfer\",\n",
    "            \"pin_blocked\",\n",
    "            \"receiving_money\",\n",
    "            \"Refund_not_showing_up\",\n",
    "            \"request_refund\",\n",
    "            \"reverted_card_payment?\",\n",
    "            \"supported_cards_and_currencies\",\n",
    "            \"terminate_account\",\n",
    "            \"top_up_by_bank_transfer_charge\",\n",
    "            \"top_up_by_card_charge\",\n",
    "            \"top_up_by_cash_or_cheque\",\n",
    "            \"top_up_failed\",\n",
    "            \"top_up_limits\",\n",
    "            \"top_up_reverted\",\n",
    "            \"topping_up_by_card\",\n",
    "            \"transaction_charged_twice\",\n",
    "            \"transfer_fee_charged\",\n",
    "            \"transfer_into_account\",\n",
    "            \"transfer_not_received_by_recipient\",\n",
    "            \"transfer_timing\",\n",
    "            \"unable_to_verify_identity\",\n",
    "            \"verify_my_identity\",\n",
    "            \"verify_source_of_funds\",\n",
    "            \"verify_top_up\",\n",
    "            \"virtual_card_not_working\",\n",
    "            \"visa_or_mastercard\",\n",
    "            \"why_verify_identity\",\n",
    "            \"wrong_amount_of_cash_received\",\n",
    "            \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "        ],\n",
    "        \"few_shot_examples\": \"../data/banking_seed.csv\",\n",
    "        \"few_shot_selection\": \"semantic_similarity\",\n",
    "        \"few_shot_num\": 10,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a53186c-4fd2-46c2-b283-944b1ca9c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_similarity_few_shot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e87c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b41c631b75405bbf5cfbe395a7cf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.335\n",
      "Number of examples to label: 100\n",
      "Average cost per example: $0.00335\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/banking_test.csv', max_items=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca976604-a13c-42a7-a380-7a27d3d3b8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba1695d5b77401d9f3020dfce299e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:34:33 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e11925cc2fabd92886b2f3e409c2ad91 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:34:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e11925cc2fabd92886b2f3e409c2ad91 in your message.).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:36:25 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69fcbeffe64c68718042a602a2225641 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:36:25 langchain.embeddings.openai WARNING: Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69fcbeffe64c68718042a602a2225641 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69fcbeffe64c68718042a602a2225641 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 69fcbeffe64c68718042a602a2225641 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:36:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'refuel', 'openai-processing-ms': '30010', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '69fcbeffe64c68718042a602a2225641', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb23bfaea515cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:37:01 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bc8355e65dfbeeb79b720ce46a4a0198 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:37:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bc8355e65dfbeeb79b720ce46a4a0198 in your message.).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:07 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f646166cd3c8476da173f5011db9e31 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:07 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f646166cd3c8476da173f5011db9e31 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f646166cd3c8476da173f5011db9e31 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1f646166cd3c8476da173f5011db9e31 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '109', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '46944', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '28.703s', 'x-request-id': '1f646166cd3c8476da173f5011db9e31', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb28708a3015cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:13 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b75a3be3634804037ebfea9bbc38a663 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:13 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b75a3be3634804037ebfea9bbc38a663 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b75a3be3634804037ebfea9bbc38a663 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b75a3be3634804037ebfea9bbc38a663 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '192', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '46345', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '29.103s', 'x-request-id': 'b75a3be3634804037ebfea9bbc38a663', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb2892d8f315cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:15 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 661d488d8cc64ec8a9cc64cc6ace6243 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:15 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 661d488d8cc64ec8a9cc64cc6ace6243 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 661d488d8cc64ec8a9cc64cc6ace6243 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 661d488d8cc64ec8a9cc64cc6ace6243 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '113', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '44688', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '30.207s', 'x-request-id': '661d488d8cc64ec8a9cc64cc6ace6243', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb28a1c9a315cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:17 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a87ed5d1bdd0e72cf4284b8e58054b6e in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:17 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a87ed5d1bdd0e72cf4284b8e58054b6e in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a87ed5d1bdd0e72cf4284b8e58054b6e in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a87ed5d1bdd0e72cf4284b8e58054b6e in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:17 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '92', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '43399', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '31.066s', 'x-request-id': 'a87ed5d1bdd0e72cf4284b8e58054b6e', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb28ab7ca915cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:20 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccc86f7092340078045cd675035d9451 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:20 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccc86f7092340078045cd675035d9451 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccc86f7092340078045cd675035d9451 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ccc86f7092340078045cd675035d9451 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '117', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '44428', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '30.38s', 'x-request-id': 'ccc86f7092340078045cd675035d9451', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb28be895f15cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:39:21 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d91b408446237e8ef2640b27f87f7d48 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:39:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d91b408446237e8ef2640b27f87f7d48 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d91b408446237e8ef2640b27f87f7d48 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d91b408446237e8ef2640b27f87f7d48 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:39:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '110', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '43445', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '31.036s', 'x-request-id': 'd91b408446237e8ef2640b27f87f7d48', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb28c8bcb015cc-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 0.42560799999999993\n",
      "Metric: support: [(500, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.772, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea85e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Davinci\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "config_v4 = deepcopy(config_similarity_few_shot)\n",
    "\n",
    "config_v4['model'] = {'provider': 'openai', 'name': 'text-davinci-003'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f745f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "486b4232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef58d4e6e054066b991560837405dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $19.277\n",
      "Number of examples to label: 500\n",
      "Average cost per example: $0.03855\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/banking_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd143f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb84705a7594867bd15597fe8ce53da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:54:29 openai INFO: error_code=None error_message='Request failed due to server shutdown' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 17:54:29 langchain.llms.openai WARNING: Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Request failed due to server shutdown {\n",
      "  \"error\": {\n",
      "    \"message\": \"Request failed due to server shutdown\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'Request failed due to server shutdown', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 00:54:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '141', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'text-davinci-003', 'openai-organization': 'refuel', 'openai-processing-ms': '2664', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '245000', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '1.2s', 'x-request-id': 'b739c7b5fe301bac031bd32b80d22647', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb3edfc9bafa01-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 9.71642\n",
      "Metric: support: [(1000, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.779, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "866f8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_v5 = deepcopy(config_similarity_few_shot)\n",
    "\n",
    "config_v5['model'] = {'provider': 'anthropic', 'name': 'claude-v1'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e663c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f75d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b99f2f29ab4c9fad90a96e09354b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.425\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.04248\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/banking_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3be6bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:13:46.837 | INFO     | autolabel.labeler:run:137 - Task run already exists.\n",
      "There is an existing task with following details: id='3143625989' created_at=datetime.datetime(2023, 5, 30, 18, 7, 40, 919962) task_id='51d5fc05d9b07351245e0bd41f9e7434' dataset_id='7a7ef3f81d1078751194b3e986ff48bf' current_index=35 output_file='../data/banking_test_labeled.csv' status=<TaskStatus.ACTIVE: 'active'> error=None metrics=None\n",
      "Evaluating the existing task...\n",
      "Metric: support: [(40, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.725, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "40 examples have been labeled so far.\n",
      "Last annotated example - Prompt: You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: The app made a mistake and said I made a cash withdrawal.\n",
      "Output: cash_withdrawal_not_recognised\n",
      "\n",
      "Input: I have a payment listed in error.\n",
      "Output: card_payment_not_recognised\n",
      "\n",
      "Input: The rate of exchange for my card payment is incorrect\n",
      "Output: card_payment_wrong_exchange_rate\n",
      "\n",
      "Input: My transaction to pay for an item was returned to my account.\n",
      "Output: reverted_card_payment?\n",
      "\n",
      "Input: I took out money from a transaction machine and it exchanged the wrong dollar value amount from another currency!\n",
      "Output: wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "Input: I made a payment but the app reverted the payment.\n",
      "Output: reverted_card_payment?\n",
      "\n",
      "Input: I tried to take out cash but the amount isn't right, so what do I do?\n",
      "Output: wrong_amount_of_cash_received\n",
      "\n",
      "Input: I believe my card payment exchange rate is incorrect.\n",
      "Output: card_payment_wrong_exchange_rate\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I made a mistake and need to cancel a transaction\n",
      "Output: \n",
      "Annotation: cancel_transfer\n",
      "Resuming the task...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a37f17ef254857ac1457a5b1d09f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:33:42 openai INFO: error_code=None error_message='The server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists.' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 18:33:42 langchain.embeddings.openai WARNING: Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 18:34:16 openai INFO: error_code=None error_message='The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d81d230f052743cc6bf95f0632c1b236 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 18:34:16 langchain.embeddings.openai WARNING: Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d81d230f052743cc6bf95f0632c1b236 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d81d230f052743cc6bf95f0632c1b236 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d81d230f052743cc6bf95f0632c1b236 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 01:34:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'refuel', 'openai-processing-ms': '30008', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'd81d230f052743cc6bf95f0632c1b236', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cfb787d985815ea-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 8.988903040000002\n",
      "Metric: support: [(1000, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.808, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "232114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_v6 = deepcopy(config_similarity_few_shot)\n",
    "\n",
    "config_v6['model'] = {'provider': 'openai', 'name': 'gpt-4'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b56cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autolabel.models.openai.OpenAILLM at 0x28c47abb0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = LabelingAgent(config_v6)\n",
    "agent.llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11b77062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5896800243475fadd2d624b5768d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.804\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.0804\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/banking_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6fef630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a20bd90636944b3bd243980224666d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:14:48 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:14:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 03:14:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7cfc04dfae71faa6-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:19:47 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:19:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:19:55 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:19:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:19:57 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:19:57 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:02 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:02 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:08 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:12 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:13 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:13 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:53 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:53 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:20:55 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:20:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:01 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:03 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:03 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:08 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:14 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:14 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:16 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:16 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:17 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:17 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:33 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:35 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:35 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:56 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:56 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:21:58 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:21:58 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:01 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:09 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:09 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:21 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:22 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:22 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:47 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:22:48 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:22:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:07 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:07 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:28 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:28 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:40 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:40 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:43 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:43 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:44 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:44 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:57 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:57 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:23:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:23:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:12 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:17 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:17 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:19 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:19 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:22 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:22 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:23 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:23 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:35 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:35 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:38 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:54 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:24:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:24:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:05 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:05 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:10 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:10 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:14 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:14 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:16 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:16 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:22 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:22 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:23 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:23 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:31 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:31 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:35 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:35 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:41 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:41 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:42 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:42 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:49 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:49 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:51 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:51 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:53 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:53 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:25:54 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:25:54 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:00 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:00 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:07 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:07 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:10 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:10 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:23 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:23 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:33 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:48 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:54 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:54 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:26:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:26:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:01 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:02 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:02 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:39 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:39 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:42 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:42 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:49 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:49 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:53 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:53 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:27:55 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:27:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:08 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:18 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:18 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:21 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:35 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:35 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:43 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:43 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:45 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:47 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:28:56 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:28:56 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:29:01 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:29:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:29:11 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:29:11 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:29:14 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:29:14 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:32 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:37 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:37 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:38 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:42 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:42 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:45 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:30:56 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:30:56 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:31:06 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:31:06 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:31:09 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:31:09 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:31:51 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:31:51 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:31:59 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:12 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:32:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:24 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:32:24 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:25 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:25 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:37 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:32:37 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:40 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:32:40 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:41 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:56 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:32:56 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:04 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:07 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:07 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:19 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:20 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:20 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:28 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:28 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:30 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:33 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:36 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:41 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:41 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:45 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:46 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:33:46 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:34:20 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:34:20 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:34:25 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:34:25 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:34:28 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:34:28 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:34:41 openai INFO: error_code=None error_message='Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-05-30 20:34:41 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-4 in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 40000 / min. Please try again in 1ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 10.230660000000004\n",
      "Metric: support: [(500, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.816, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0                        terminate_account\n",
       " 1                   cash_withdrawal_charge\n",
       " 2      direct_debit_payment_not_recognised\n",
       " 3                 card_payment_fee_charged\n",
       " 4                extra_charge_on_statement\n",
       "                       ...                 \n",
       " 495                            pin_blocked\n",
       " 496               card_payment_fee_charged\n",
       " 497                        transfer_timing\n",
       " 498                  edit_personal_details\n",
       " 499                pending_cash_withdrawal\n",
       " Name: BankingComplaintsClassification_llm_label, Length: 500, dtype: object,\n",
       "                                                example  \\\n",
       " 0                           I want to close my account   \n",
       " 1    It seems I was overcharged when I used an ATM ...   \n",
       " 2    I have a direct debit transaction I have not s...   \n",
       " 3      How much does it cost in fees to use your card?   \n",
       " 4                          There is an extra $1 charge   \n",
       " ..                                                 ...   \n",
       " 495                    Are you able to unblock my pin?   \n",
       " 496  I was charged a fee after using my card and I ...   \n",
       " 497  I initiated a Bank transfer form Europe, how l...   \n",
       " 498                    My address needs to be revised.   \n",
       " 499  How long with my cash withdrawal stay pending ...   \n",
       " \n",
       "                                        label  \\\n",
       " 0                          terminate_account   \n",
       " 1    wrong_exchange_rate_for_cash_withdrawal   \n",
       " 2        direct_debit_payment_not_recognised   \n",
       " 3                        order_physical_card   \n",
       " 4                  extra_charge_on_statement   \n",
       " ..                                       ...   \n",
       " 495                              pin_blocked   \n",
       " 496                 card_payment_fee_charged   \n",
       " 497                          transfer_timing   \n",
       " 498                    edit_personal_details   \n",
       " 499                  pending_cash_withdrawal   \n",
       " \n",
       "     BankingComplaintsClassification_llm_labeled_successfully  \\\n",
       " 0                                                  yes         \n",
       " 1                                                  yes         \n",
       " 2                                                  yes         \n",
       " 3                                                  yes         \n",
       " 4                                                  yes         \n",
       " ..                                                 ...         \n",
       " 495                                                yes         \n",
       " 496                                                yes         \n",
       " 497                                                yes         \n",
       " 498                                                yes         \n",
       " 499                                                yes         \n",
       " \n",
       "     BankingComplaintsClassification_llm_label  \n",
       " 0                           terminate_account  \n",
       " 1                      cash_withdrawal_charge  \n",
       " 2         direct_debit_payment_not_recognised  \n",
       " 3                    card_payment_fee_charged  \n",
       " 4                   extra_charge_on_statement  \n",
       " ..                                        ...  \n",
       " 495                               pin_blocked  \n",
       " 496                  card_payment_fee_charged  \n",
       " 497                           transfer_timing  \n",
       " 498                     edit_personal_details  \n",
       " 499                   pending_cash_withdrawal  \n",
       " \n",
       " [500 rows x 4 columns],\n",
       " [MetricResult(metric_type=<Metric.SUPPORT: 'support'>, name='support', value=[(500, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.THRESHOLD: 'threshold'>, name='threshold', value=[(-inf, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.ACCURACY: 'accuracy'>, name='accuracy', value=[(0.816, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.COMPLETION_RATE: 'completion_rate'>, name='completion_rate', value=[(1.0, 'index=0')])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('../data/banking_test.csv', max_items=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9cae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "config_refuel = deepcopy(config_similarity_few_shot)\n",
    "\n",
    "config_refuel['model'] = {'provider': 'refuel', 'name': 'flan-t5-xxl'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f187723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autolabel.models.refuel.RefuelLLM at 0x289aa2520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = LabelingAgent(config_refuel)\n",
    "agent.llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e7b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "722863b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:00:00 langchain.embeddings.openai WARNING: Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b39dc95f10e4ee6af699fb6f7630522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.0\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.0\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/banking_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e65d6238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7beff11ea4a949698e0a2bbd6743b495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:01:27.362 | WARNING  | tenacity.before_sleep:log_it:65 - Retrying autolabel.models.refuel.RefuelLLM._label_with_retry in 2.0 seconds as it raised HTTPError: 502 Server Error: Bad Gateway for url: https://llm.refuel.ai/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:01:29.599 | WARNING  | tenacity.before_sleep:log_it:65 - Retrying autolabel.models.refuel.RefuelLLM._label_with_retry in 2.0 seconds as it raised HTTPError: 502 Server Error: Bad Gateway for url: https://llm.refuel.ai/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:01:31.806 | WARNING  | tenacity.before_sleep:log_it:65 - Retrying autolabel.models.refuel.RefuelLLM._label_with_retry in 4.0 seconds as it raised HTTPError: 502 Server Error: Bad Gateway for url: https://llm.refuel.ai/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:01:36.023 | WARNING  | tenacity.before_sleep:log_it:65 - Retrying autolabel.models.refuel.RefuelLLM._label_with_retry in 8.0 seconds as it raised HTTPError: 502 Server Error: Bad Gateway for url: https://llm.refuel.ai/.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b7/0vm4npf94l13qvplgklkmzj40000gn/T/ipykernel_17956/2431961806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/banking_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/autolabel/labeler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataset, max_items, output_name, start_index, eval_every)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;31m# Get response from LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0;31m# TODO (dhruva): We need to handle this case carefully\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/autolabel/models/base.py\u001b[0m in \u001b[0;36mlabel\u001b[0;34m(self, prompts)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# label missing prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_prompts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mnew_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 cost += self.get_cost(\n",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/autolabel/models/refuel.py\u001b[0m in \u001b[0;36m_label\u001b[0;34m(self, prompts)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mgenerations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/refuel-ai.nosync/virtualenv/lib/python3.8/site-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/banking_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6303044-13a9-4a00-a1e5-45f89c667691",
   "metadata": {},
   "source": [
    "## Confidence estimation\n",
    "Let's try to see if the model is able to do well on confidence estimation, if the model knows what it doesn't know we might be able to trade off completion rate for accuracy and get a higher accuracy even though we may be labeling less amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45440e40-3d0c-411a-8b3c-cad1219f2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = {\n",
    "    \"project_name\": \"BankingClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"prefix_prompt\": \"You are an expert at understanding twitter complaints.\",\n",
    "    \"example_selector\": {\n",
    "        \"strategy\": \"semantic_similarity\",\n",
    "        \"num_examples\": 4\n",
    "    },\n",
    "    \"compute_confidence\": \"True\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0901c46-e9ba-4651-b857-dced623d93fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:24<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.135\n",
      "Number of examples to label: 100\n",
      "Average cost per example: $0.00135\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding twitter complaints.\n",
      "Your job is to correctly label the provided input example into one of the following 77 categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "\n",
      "You will return the answer in JSON format with one key: {\"label\": \"the correct label\"}\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "Example: I would like to delete my account please.\n",
      "Output: \n",
      "{\"label\": \"terminate_account\"}\n",
      "\n",
      "Example: Can you help me get rid of my account?\n",
      "Output: \n",
      "{\"label\": \"terminate_account\"}\n",
      "\n",
      "Example: Help me cancel my transaction\n",
      "Output: \n",
      "{\"label\": \"cancel_transfer\"}\n",
      "\n",
      "Example: I need to cancel a purchase I made.\n",
      "Output: \n",
      "{\"label\": \"request_refund\"}\n",
      "\n",
      "Now I want you to label the following example: Example: I want to close my account\n",
      "Output: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "o = LabelingAgent(task_config, llm_config)\n",
    "o.plan('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7733dbd5-0327-4583-b7d2-e9d949dc54ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-08 22:21:12.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrefuel_oracle.oracle\u001b[0m:\u001b[36mannotate\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mTask run already exists.\u001b[0m\n",
      "There is an existing task with following details: id='4220919502' created_at=datetime.datetime(2023, 5, 8, 22, 12, 21, 695444) task_id='fe18616c502136eecf138fd6f0fbd7a9' dataset_id='8d146e04eeed04671abdece0f40e0469' current_index=65 output_file='data/banking_test_labeled.csv' status=<TaskStatus.ACTIVE: 'active'> error=None metrics=None\n",
      "Evaluating the existing task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.9310009718172984\n",
      "Metric: support: [(70, 'index=0'), (0, 'index=1'), (1, 'index=2'), (19, 'index=3'), (20, 'index=4'), (39, 'index=5'), (40, 'index=6'), (41, 'index=7'), (43, 'index=8'), (50, 'index=9'), (52, 'index=10'), (53, 'index=11'), (55, 'index=12'), (57, 'index=13'), (70, 'index=14')]\n",
      "Metric: threshold: [(-inf, 'index=0'), (3.7169041911318668, 'index=1'), (2.7169041911318668, 'index=2'), (2.7095740903214547, 'index=3'), (2.709052961047316, 'index=4'), (2.6906020486746898, 'index=5'), (2.6903324708649907, 'index=6'), (2.687156017308222, 'index=7'), (2.6787913093093048, 'index=8'), (2.630019572879165, 'index=9'), (2.5956249750404234, 'index=10'), (2.5799757948748283, 'index=11'), (2.568780087012188, 'index=12'), (2.5532547033659325, 'index=13'), (2.2109919215757605, 'index=14')]\n",
      "Metric: accuracy: [(0.7, 'index=0'), (nan, 'index=1'), (1.0, 'index=2'), (1.0, 'index=3'), (0.95, 'index=4'), (0.9743589743589743, 'index=5'), (0.95, 'index=6'), (0.9512195121951219, 'index=7'), (0.9069767441860465, 'index=8'), (0.92, 'index=9'), (0.8846153846153846, 'index=10'), (0.8867924528301887, 'index=11'), (0.8545454545454545, 'index=12'), (0.8596491228070176, 'index=13'), (0.7, 'index=14')]\n",
      "Metric: completion_rate: [(1.0, 'index=0'), (0.0, 'index=1'), (0.014285714285714285, 'index=2'), (0.2714285714285714, 'index=3'), (0.2857142857142857, 'index=4'), (0.5571428571428572, 'index=5'), (0.5714285714285714, 'index=6'), (0.5857142857142857, 'index=7'), (0.6142857142857143, 'index=8'), (0.7142857142857143, 'index=9'), (0.7428571428571429, 'index=10'), (0.7571428571428571, 'index=11'), (0.7857142857142857, 'index=12'), (0.8142857142857143, 'index=13'), (1.0, 'index=14')]\n",
      "70 examples have been labeled so far.\n",
      "Last annotated example - Prompt: You are an expert at understanding twitter complaints.\n",
      "Your job is to correctly label the provided input example into one of the following 77 categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "\n",
      "You will return the answer in JSON format with one key: {\"label\": \"the correct label\"}\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "Example: How do I link to my credit card with you?\n",
      "Output: \n",
      "{\"label\": \"card_linking\"}\n",
      "\n",
      "Example: I found my card, I would like to reactivate it.\n",
      "Output: \n",
      "{\"label\": \"card_linking\"}\n",
      "\n",
      "Example: How can I activate my card>\n",
      "Output: \n",
      "{\"label\": \"activate_my_card\"}\n",
      "\n",
      "Example: How do you get a virtual card?\n",
      "Output: \n",
      "{\"label\": \"getting_virtual_card\"}\n",
      "\n",
      "Now I want you to label the following example: Example: How do I add the card to my account?\n",
      "Output: \n",
      "\n",
      "\n",
      "Annotation: card_linking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to resume it? (y/n) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming the task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:48<00:00,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.9205333333333333\n",
      "Metric: support: [(100, 'index=0'), (0, 'index=1'), (1, 'index=2'), (29, 'index=3'), (30, 'index=4'), (35, 'index=5'), (36, 'index=6'), (61, 'index=7'), (62, 'index=8'), (64, 'index=9'), (66, 'index=10'), (76, 'index=11'), (79, 'index=12'), (80, 'index=13'), (82, 'index=14'), (85, 'index=15'), (100, 'index=16')]\n",
      "Metric: threshold: [(-inf, 'index=0'), (3.716918815608781, 'index=1'), (2.716918815608781, 'index=2'), (2.7095342984271964, 'index=3'), (2.709052961047316, 'index=4'), (2.7074403430995178, 'index=5'), (2.70737698174731, 'index=6'), (2.6906020486746898, 'index=7'), (2.6903324708649907, 'index=8'), (2.6864060122848614, 'index=9'), (2.6787913093093048, 'index=10'), (2.6220833554670904, 'index=11'), (2.5956249750404234, 'index=12'), (2.5799757948748283, 'index=13'), (2.568780087012188, 'index=14'), (2.5532547033659325, 'index=15'), (2.2109919215757605, 'index=16')]\n",
      "Metric: accuracy: [(0.75, 'index=0'), (nan, 'index=1'), (1.0, 'index=2'), (1.0, 'index=3'), (0.9666666666666667, 'index=4'), (0.9714285714285714, 'index=5'), (0.9444444444444444, 'index=6'), (0.9672131147540983, 'index=7'), (0.9516129032258065, 'index=8'), (0.953125, 'index=9'), (0.9242424242424242, 'index=10'), (0.9342105263157895, 'index=11'), (0.8987341772151899, 'index=12'), (0.9, 'index=13'), (0.8780487804878049, 'index=14'), (0.8823529411764706, 'index=15'), (0.75, 'index=16')]\n",
      "Metric: completion_rate: [(1.0, 'index=0'), (0.0, 'index=1'), (0.01, 'index=2'), (0.29, 'index=3'), (0.3, 'index=4'), (0.35, 'index=5'), (0.36, 'index=6'), (0.61, 'index=7'), (0.62, 'index=8'), (0.64, 'index=9'), (0.66, 'index=10'), (0.76, 'index=11'), (0.79, 'index=12'), (0.8, 'index=13'), (0.82, 'index=14'), (0.85, 'index=15'), (1.0, 'index=16')]\n",
      "Total number of failures: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = o.run('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9435243-5df4-4654-a770-6c832d2ee916",
   "metadata": {},
   "source": [
    "## Chain of thought reasoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1060411-126c-4c3f-8bc3-452babc0fe20",
   "metadata": {},
   "source": [
    "Chain of thought requires an explanation for every seed example. As we don't have the explanations or the domain knowledge to construct these explanations, we can use the model to generate the explanations and then use these explanations as an input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46694f24-eb6f-45af-82e2-2f66c106bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"labels_list\": [\n",
    "        \"activate_my_card\",\n",
    "        \"age_limit\",\n",
    "        \"apple_pay_or_google_pay\",\n",
    "        \"atm_support\",\n",
    "        \"automatic_top_up\",\n",
    "        \"balance_not_updated_after_bank_transfer\",\n",
    "        \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "        \"beneficiary_not_allowed\",\n",
    "        \"cancel_transfer\",\n",
    "        \"card_about_to_expire\",\n",
    "        \"card_acceptance\",\n",
    "        \"card_arrival\",\n",
    "        \"card_delivery_estimate\",\n",
    "        \"card_linking\",\n",
    "        \"card_not_working\",\n",
    "        \"card_payment_fee_charged\",\n",
    "        \"card_payment_not_recognised\",\n",
    "        \"card_payment_wrong_exchange_rate\",\n",
    "        \"card_swallowed\",\n",
    "        \"cash_withdrawal_charge\",\n",
    "        \"cash_withdrawal_not_recognised\",\n",
    "        \"change_pin\",\n",
    "        \"compromised_card\",\n",
    "        \"contactless_not_working\",\n",
    "        \"country_support\",\n",
    "        \"declined_card_payment\",\n",
    "        \"declined_cash_withdrawal\",\n",
    "        \"declined_transfer\",\n",
    "        \"direct_debit_payment_not_recognised\",\n",
    "        \"disposable_card_limits\",\n",
    "        \"edit_personal_details\",\n",
    "        \"exchange_charge\",\n",
    "        \"exchange_rate\",\n",
    "        \"exchange_via_app\",\n",
    "        \"extra_charge_on_statement\",\n",
    "        \"failed_transfer\",\n",
    "        \"fiat_currency_support\",\n",
    "        \"get_disposable_virtual_card\",\n",
    "        \"get_physical_card\",\n",
    "        \"getting_spare_card\",\n",
    "        \"getting_virtual_card\",\n",
    "        \"lost_or_stolen_card\",\n",
    "        \"lost_or_stolen_phone\",\n",
    "        \"order_physical_card\",\n",
    "        \"passcode_forgotten\",\n",
    "        \"pending_card_payment\",\n",
    "        \"pending_cash_withdrawal\",\n",
    "        \"pending_top_up\",\n",
    "        \"pending_transfer\",\n",
    "        \"pin_blocked\",\n",
    "        \"receiving_money\",\n",
    "        \"Refund_not_showing_up\",\n",
    "        \"request_refund\",\n",
    "        \"reverted_card_payment?\",\n",
    "        \"supported_cards_and_currencies\",\n",
    "        \"terminate_account\",\n",
    "        \"top_up_by_bank_transfer_charge\",\n",
    "        \"top_up_by_card_charge\",\n",
    "        \"top_up_by_cash_or_cheque\",\n",
    "        \"top_up_failed\",\n",
    "        \"top_up_limits\",\n",
    "        \"top_up_reverted\",\n",
    "        \"topping_up_by_card\",\n",
    "        \"transaction_charged_twice\",\n",
    "        \"transfer_fee_charged\",\n",
    "        \"transfer_into_account\",\n",
    "        \"transfer_not_received_by_recipient\",\n",
    "        \"transfer_timing\",\n",
    "        \"unable_to_verify_identity\",\n",
    "        \"verify_my_identity\",\n",
    "        \"verify_source_of_funds\",\n",
    "        \"verify_top_up\",\n",
    "        \"virtual_card_not_working\",\n",
    "        \"visa_or_mastercard\",\n",
    "        \"why_verify_identity\",\n",
    "        \"wrong_amount_of_cash_received\",\n",
    "        \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "    ],\n",
    "    \"dataset_schema\": {\n",
    "        \"input_columns\": [\n",
    "            \"example\"\n",
    "        ],\n",
    "        \"label_column\": \"label\"\n",
    "    },\n",
    "    \"seed_examples\": [\n",
    "        {\n",
    "            \"example\": \"Is it free to transfer money or is there a fee?\",\n",
    "            \"label\": \"transfer_fee_charged\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"I need my PIN, where is it?\",\n",
    "            \"label\": \"get_physical_card\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"Can my salary be received and transferred to my current currency in my country?\",\n",
    "            \"label\": \"receiving_money\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"Why isn't my purchase exchange rate correct?\",\n",
    "            \"label\": \"card_payment_wrong_exchange_rate\"\n",
    "        },\n",
    "        {\n",
    "            \"example\": \"Why was I charged a fee on a cash withdrawal?\",\n",
    "            \"label\": \"cash_withdrawal_charge\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea7ce1ab-9fbf-4b58-a0d0-67ca0bea14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = {\n",
    "    \"project_name\": \"BankingClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"prefix_prompt\": \"You are an expert at understanding twitter complaints.\",\n",
    "    \"chain_of_thought\": \"True\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "946d7d72-4c23-4140-8ad0-e574117160f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-08 22:31:40.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrefuel_oracle.oracle\u001b[0m:\u001b[36mgenerate_explanations\u001b[0m:\u001b[36m423\u001b[0m - \u001b[1mChain of thought requires explanations for seed examples. Generating explanations for seed examples.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:13<00:00,  2.80s/it]\n",
      "100%|| 20/20 [00:00<00:00, 244.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.179\n",
      "Number of examples to label: 100\n",
      "Average cost per example: $0.00179\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding twitter complaints.\n",
      "Your job is to correctly label the provided input example into one of the following 77 categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "\n",
      "You will return the answer in JSON format with one key: {\"label\": \"the correct label\"}\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "Example: Is it free to transfer money or is there a fee?\n",
      "Output: Let's think step by step.\n",
      "The output is transfer_fee_charged because the user is asking if there is a fee for transferring money. This category specifically deals with complaints about fees charged for topping up or transferring money. So, the answer is transfer_fee_charged.\n",
      "{\"label\": \"transfer_fee_charged\"}\n",
      "\n",
      "Example: I need my PIN, where is it?\n",
      "Output: Let's think step by step.\n",
      "The user is asking for their PIN, which suggests they have not yet received their physical card. Therefore, the appropriate category is \"get_physical_card\". So, the answer is get_physical_card.\n",
      "{\"label\": \"get_physical_card\"}\n",
      "\n",
      "Example: Can my salary be received and transferred to my current currency in my country?\n",
      "Output: Let's think step by step.\n",
      "The user is asking about receiving their salary and transferring it to their current currency in their country. This falls under the category of receiving_money as it pertains to receiving funds and transferring them. So, the answer is receiving_money.\n",
      "{\"label\": \"receiving_money\"}\n",
      "\n",
      "Example: Why isn't my purchase exchange rate correct?\n",
      "Output: Let's think step by step.\n",
      "The output is card_payment_wrong_exchange_rate because the complaint is specifically about the exchange rate for a card payment, indicating that the user believes they were charged an incorrect rate. This is a separate issue from other types of exchange rate complaints, such as those related to cash withdrawals. So, the answer is card_payment_wrong_exchange_rate.\n",
      "{\"label\": \"card_payment_wrong_exchange_rate\"}\n",
      "\n",
      "Now I want you to label the following example: Example: I want to close my account\n",
      "Output: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "o = LabelingAgent(task_config, llm_config)\n",
    "o.plan('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33b1a3f8-430a-4bf5-a60a-ca341d57f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00, 108660.73it/s]\n",
      " 25%|       | 5/20 [01:24<04:07, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-08 22:33:56.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrefuel_oracle.tasks.base\u001b[0m:\u001b[36mparse_json_llm_response\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mError parsing LLM response: Let's think step by step.\n",
      "This is not a complaint or issue related to any of the provided categories. It is a general question about the difference between two types of delivery options. Therefore, it does not fit into any of the categories and cannot be labeled.. AttributeError(\"'NoneType' object has no attribute 'strip'\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 16/20 [04:47<01:16, 19.11s/it]2023-05-08 22:37:33 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 289fb6d43caca91739ab3cbe2192a97f in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-08 22:37:33 /home/ubuntu/.local/lib/python3.8/site-packages/langchain/chat_models/openai.py WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 289fb6d43caca91739ab3cbe2192a97f in your message.).\n",
      "100%|| 20/20 [06:34<00:00, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: support: [(99, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.696969696969697, 'index=0')]\n",
      "Metric: completion_rate: [(0.99, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = o.run('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08355115-45fc-4719-9111-44883085ada2",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "I am noting a few things that I did not try out, but would have wanted to try to boost completion rate while keeping the accuracy high\n",
    "\n",
    "1. Wanted to try chain of thought reasoning with a semantic similarity example selector\n",
    "2. Increase the number of seed examples to be close to one example per class\n",
    "3. Find the annotator guidelines and pass these as part of the prompt to the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3dcb74e-2b04-4e73-b303-575e29f52f3c",
   "metadata": {},
   "source": [
    "Trying out all bells and whistles together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce66e52a-2925-477b-9b21-0558201e233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"labels_list\": [\n",
    "        \"activate_my_card\",\n",
    "        \"age_limit\",\n",
    "        \"apple_pay_or_google_pay\",\n",
    "        \"atm_support\",\n",
    "        \"automatic_top_up\",\n",
    "        \"balance_not_updated_after_bank_transfer\",\n",
    "        \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "        \"beneficiary_not_allowed\",\n",
    "        \"cancel_transfer\",\n",
    "        \"card_about_to_expire\",\n",
    "        \"card_acceptance\",\n",
    "        \"card_arrival\",\n",
    "        \"card_delivery_estimate\",\n",
    "        \"card_linking\",\n",
    "        \"card_not_working\",\n",
    "        \"card_payment_fee_charged\",\n",
    "        \"card_payment_not_recognised\",\n",
    "        \"card_payment_wrong_exchange_rate\",\n",
    "        \"card_swallowed\",\n",
    "        \"cash_withdrawal_charge\",\n",
    "        \"cash_withdrawal_not_recognised\",\n",
    "        \"change_pin\",\n",
    "        \"compromised_card\",\n",
    "        \"contactless_not_working\",\n",
    "        \"country_support\",\n",
    "        \"declined_card_payment\",\n",
    "        \"declined_cash_withdrawal\",\n",
    "        \"declined_transfer\",\n",
    "        \"direct_debit_payment_not_recognised\",\n",
    "        \"disposable_card_limits\",\n",
    "        \"edit_personal_details\",\n",
    "        \"exchange_charge\",\n",
    "        \"exchange_rate\",\n",
    "        \"exchange_via_app\",\n",
    "        \"extra_charge_on_statement\",\n",
    "        \"failed_transfer\",\n",
    "        \"fiat_currency_support\",\n",
    "        \"get_disposable_virtual_card\",\n",
    "        \"get_physical_card\",\n",
    "        \"getting_spare_card\",\n",
    "        \"getting_virtual_card\",\n",
    "        \"lost_or_stolen_card\",\n",
    "        \"lost_or_stolen_phone\",\n",
    "        \"order_physical_card\",\n",
    "        \"passcode_forgotten\",\n",
    "        \"pending_card_payment\",\n",
    "        \"pending_cash_withdrawal\",\n",
    "        \"pending_top_up\",\n",
    "        \"pending_transfer\",\n",
    "        \"pin_blocked\",\n",
    "        \"receiving_money\",\n",
    "        \"Refund_not_showing_up\",\n",
    "        \"request_refund\",\n",
    "        \"reverted_card_payment?\",\n",
    "        \"supported_cards_and_currencies\",\n",
    "        \"terminate_account\",\n",
    "        \"top_up_by_bank_transfer_charge\",\n",
    "        \"top_up_by_card_charge\",\n",
    "        \"top_up_by_cash_or_cheque\",\n",
    "        \"top_up_failed\",\n",
    "        \"top_up_limits\",\n",
    "        \"top_up_reverted\",\n",
    "        \"topping_up_by_card\",\n",
    "        \"transaction_charged_twice\",\n",
    "        \"transfer_fee_charged\",\n",
    "        \"transfer_into_account\",\n",
    "        \"transfer_not_received_by_recipient\",\n",
    "        \"transfer_timing\",\n",
    "        \"unable_to_verify_identity\",\n",
    "        \"verify_my_identity\",\n",
    "        \"verify_source_of_funds\",\n",
    "        \"verify_top_up\",\n",
    "        \"virtual_card_not_working\",\n",
    "        \"visa_or_mastercard\",\n",
    "        \"why_verify_identity\",\n",
    "        \"wrong_amount_of_cash_received\",\n",
    "        \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "    ],\n",
    "    \"dataset_schema\": {\n",
    "        \"input_columns\": [\n",
    "            \"example\"\n",
    "        ],\n",
    "        \"label_column\": \"label\"\n",
    "    },\n",
    "    \"seed_examples\": 'data/banking_seed.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21ec89ad-ae8a-4240-bfc2-3a2521a07d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = {\n",
    "    \"project_name\": \"BankingClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"prefix_prompt\": \"You are an expert at understanding twitter complaints.\",\n",
    "    \"example_selector\": {\n",
    "        \"strategy\": \"semantic_similarity\",\n",
    "        \"num_examples\": 4\n",
    "    },\n",
    "    \"compute_confidence\": \"True\",\n",
    "    \"chain_of_thought\": \"True\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb13fdab-dba7-4fa4-847a-3084e6673cae",
   "metadata": {},
   "source": [
    "Increase the maximum tokens allowed on the llm in case of chain of thought because some times the number of tokens produced by the llm in the explanation would exceed the default max token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "374a99f6-d1ee-4c45-a2f8-cc6f22c3516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"provider_name\": \"openai\",\n",
    "    \"model_name\": \"gpt-3.5-turbo\",\n",
    "    \"has_logprob\": False,\n",
    "    \"model_params\": {\n",
    "        \"max_tokens\": 1000, # This increases the maximum tokens\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9df8b4a6-e379-4912-84f6-c7d63b472ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 199/199 [00:00<00:00, 1434134.87it/s]\n",
      "100%|| 20/20 [00:29<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.362\n",
      "Number of examples to label: 100\n",
      "Average cost per example: $0.00362\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at understanding twitter complaints.\n",
      "Your job is to correctly label the provided input example into one of the following 77 categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "\n",
      "You will return the answer in JSON format with one key: {\"label\": \"the correct label\"}\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "Example: I would like to delete my account please.\n",
      "Output: Let's think step by step.\n",
      "The user is requesting to delete their account, which falls under the category of terminate_account. So, the answer is terminate_account.\n",
      "{\"label\": \"terminate_account\"}\n",
      "\n",
      "Example: Can you help me get rid of my account?\n",
      "Output: Let's think step by step.\n",
      "The user is requesting assistance in closing their account, which falls under the category of terminate_account. So, the answer is terminate_account.\n",
      "{\"label\": \"terminate_account\"}\n",
      "\n",
      "Example: Help me cancel my transaction\n",
      "Output: Let's think step by step.\n",
      "The user is specifically asking for help with canceling a transaction, which falls under the category of cancel_transfer. So, the answer is cancel_transfer.\n",
      "{\"label\": \"cancel_transfer\"}\n",
      "\n",
      "Example: I would like to use the bank transfer feature, but I can't find it. Can you please give me the details?\n",
      "Output: Let's think step by step.\n",
      "The user is asking about the bank transfer feature, which suggests they are having trouble transferring money into their account. The label \"transfer_into_account\" accurately describes this issue. So, the answer is transfer_into_account.\n",
      "{\"label\": \"transfer_into_account\"}\n",
      "\n",
      "Now I want you to label the following example: Example: I want to close my account\n",
      "Output: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "o = LabelingAgent(task_config, llm_config)\n",
    "o.plan('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac410611-2b8a-4728-9324-5555ecc65f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 199/199 [00:00<00:00, 1608220.61it/s]\n",
      " 20%|        | 4/20 [01:34<06:23, 23.99s/it]2023-05-08 23:10:44 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23c095ac766b84d7caf88df9a89b769a in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-05-08 23:10:44 /home/ubuntu/.local/lib/python3.8/site-packages/langchain/chat_models/openai.py WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 23c095ac766b84d7caf88df9a89b769a in your message.).\n",
      "100%|| 20/20 [08:09<00:00, 24.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.8120978120978121\n",
      "Metric: support: [(100, 'index=0'), (0, 'index=1'), (1, 'index=2'), (16, 'index=3'), (17, 'index=4'), (18, 'index=5'), (20, 'index=6'), (24, 'index=7'), (25, 'index=8'), (26, 'index=9'), (28, 'index=10'), (37, 'index=11'), (38, 'index=12'), (43, 'index=13'), (44, 'index=14'), (51, 'index=15'), (52, 'index=16'), (54, 'index=17'), (56, 'index=18'), (60, 'index=19'), (61, 'index=20'), (65, 'index=21'), (66, 'index=22'), (68, 'index=23'), (70, 'index=24'), (71, 'index=25'), (72, 'index=26'), (74, 'index=27'), (75, 'index=28'), (77, 'index=29'), (78, 'index=30'), (80, 'index=31'), (85, 'index=32'), (86, 'index=33'), (100, 'index=34')]\n",
      "Metric: threshold: [(-inf, 'index=0'), (3.71441431254104, 'index=1'), (2.71441431254104, 'index=2'), (2.5839988367995232, 'index=3'), (2.5772682289443654, 'index=4'), (2.571900894553442, 'index=5'), (2.546606833621545, 'index=6'), (2.529675078736434, 'index=7'), (2.529153546390658, 'index=8'), (2.5165535885857393, 'index=9'), (2.508399891264998, 'index=10'), (2.477808116697931, 'index=11'), (2.4747261948784813, 'index=12'), (2.453476778963486, 'index=13'), (2.4453636977542907, 'index=14'), (2.42143007673571, 'index=15'), (2.417768326992818, 'index=16'), (2.3989461883068994, 'index=17'), (2.3894358051714093, 'index=18'), (2.3715244735977126, 'index=19'), (2.369779539861716, 'index=20'), (2.3366617302871115, 'index=21'), (2.334313740287684, 'index=22'), (2.306299041534062, 'index=23'), (2.2941333327060716, 'index=24'), (2.287024449371432, 'index=25'), (2.2731511414934165, 'index=26'), (2.2634002866075797, 'index=27'), (2.244031351530027, 'index=28'), (2.226745517939451, 'index=29'), (2.225589460458993, 'index=30'), (2.1973184928341887, 'index=31'), (2.146643258680466, 'index=32'), (2.1314411659309456, 'index=33'), (1.7499458897039297, 'index=34')]\n",
      "Metric: accuracy: [(0.63, 'index=0'), (nan, 'index=1'), (1.0, 'index=2'), (1.0, 'index=3'), (0.9411764705882353, 'index=4'), (0.9444444444444444, 'index=5'), (0.85, 'index=6'), (0.875, 'index=7'), (0.84, 'index=8'), (0.8461538461538461, 'index=9'), (0.7857142857142857, 'index=10'), (0.8378378378378378, 'index=11'), (0.8157894736842105, 'index=12'), (0.8372093023255814, 'index=13'), (0.8181818181818182, 'index=14'), (0.8431372549019608, 'index=15'), (0.8269230769230769, 'index=16'), (0.8333333333333334, 'index=17'), (0.8035714285714286, 'index=18'), (0.8166666666666667, 'index=19'), (0.8032786885245902, 'index=20'), (0.8153846153846154, 'index=21'), (0.803030303030303, 'index=22'), (0.8088235294117647, 'index=23'), (0.7857142857142857, 'index=24'), (0.7887323943661971, 'index=25'), (0.7777777777777778, 'index=26'), (0.7837837837837838, 'index=27'), (0.7733333333333333, 'index=28'), (0.7792207792207793, 'index=29'), (0.7692307692307693, 'index=30'), (0.775, 'index=31'), (0.7294117647058823, 'index=32'), (0.7325581395348837, 'index=33'), (0.63, 'index=34')]\n",
      "Metric: completion_rate: [(1.0, 'index=0'), (0.0, 'index=1'), (0.01, 'index=2'), (0.16, 'index=3'), (0.17, 'index=4'), (0.18, 'index=5'), (0.2, 'index=6'), (0.24, 'index=7'), (0.25, 'index=8'), (0.26, 'index=9'), (0.28, 'index=10'), (0.37, 'index=11'), (0.38, 'index=12'), (0.43, 'index=13'), (0.44, 'index=14'), (0.51, 'index=15'), (0.52, 'index=16'), (0.54, 'index=17'), (0.56, 'index=18'), (0.6, 'index=19'), (0.61, 'index=20'), (0.65, 'index=21'), (0.66, 'index=22'), (0.68, 'index=23'), (0.7, 'index=24'), (0.71, 'index=25'), (0.72, 'index=26'), (0.74, 'index=27'), (0.75, 'index=28'), (0.77, 'index=29'), (0.78, 'index=30'), (0.8, 'index=31'), (0.85, 'index=32'), (0.86, 'index=33'), (1.0, 'index=34')]\n",
      "Total number of failures: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = o.run('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c04ce7f5-bf94-4fb2-8655-0430513d58f7",
   "metadata": {},
   "source": [
    "Increase the maximum tokens allowed on the llm in case of chain of thought because some times the number of tokens produced by the llm in the explanation would exceed the default max token limit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d71cd57f-cffb-47d7-83d2-0f272d65929e",
   "metadata": {},
   "source": [
    "## Self consistency\n",
    "\n",
    "This increases the temperature and the randomness while generating explanations allowing the model to explore multiple reasoning paths. At the end, a majority vote is taken among the generations. The llm config below generates 5 reasoning paths and takes the majority vote over these reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "392d780e-44ab-482f-8cdf-9e9b932226cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"provider_name\": \"openai\",\n",
    "    \"model_name\": \"gpt-3.5-turbo\",\n",
    "    \"has_logprob\": False,\n",
    "    \"model_params\": {\n",
    "        \"max_tokens\": 1000, # This increases the maximum tokens\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 5 # This runs self consistency\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c95fb-6a14-4df8-9090-bead4073dae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
