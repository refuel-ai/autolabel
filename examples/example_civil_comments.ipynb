{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "## Exploring the banking dataset using Autolabel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80110a5b-2b3e-45e2-a2da-f6fa00200dff",
   "metadata": {},
   "source": [
    "#### Setup the API Keys for providers that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92993c83-4473-4e05-9510-f543b070c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n",
      "env: ANTHROPIC_API_KEY=sk-ant-aRlFAviZ2o5fzmK45u-907o2f66tzxztzQUngaYnp3slkouBSSXR1sqymdK_DOk0NDj5PEfKY4yRz-a8J9BzBg\n"
     ]
    }
   ],
   "source": [
    "# %env OPENAI_API_KEY=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\n",
    "%env OPENAI_API_KEY=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\n",
    "%env ANTHROPIC_API_KEY=sk-ant-aRlFAviZ2o5fzmK45u-907o2f66tzxztzQUngaYnp3slkouBSSXR1sqymdK_DOk0NDj5PEfKY4yRz-a8J9BzBg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc861154-fcec-435b-b0ef-26fe7e695a3b",
   "metadata": {},
   "source": [
    "### Get the correct data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7de483b1-f984-44cc-81e2-68bcd07009c6",
   "metadata": {},
   "source": [
    "First lets make sure that we download the correct data. Currently data has been hosted on s3 but we will upload it to huggingface data as well in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c0274-789f-4849-8c0d-cc342c35fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://refuel-benchmarking data/ --recursive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c24be70-7b3a-42f5-856f-dbe068e7a25c",
   "metadata": {},
   "source": [
    "### Run the labeler after passing in my own seed examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "925d8a6c-a6b0-4b39-9320-c75119c58412",
   "metadata": {},
   "source": [
    "#### Create the config\n",
    "This config file has all the possible labels for the banking dataset. The model needs to choose one label from the label list provided. In input schema, we define the input columns that will be used by the oracle and the output column defines the label column, that is, the column that will be used as ground truth and will be tried to be generated by our library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97f24ce0-d507-42ec-9e22-b03d4786424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_config = {\n",
    "    \"task_name\": \"ToxicCommentClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at identifying toxic comments and understanding if a comment is sexually explicit, obscene, toxic, insults a person, demographic or race.\\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
    "        \"labels\": [\n",
    "            \"toxic\",\n",
    "            \"not toxic\"\n",
    "        ],\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f693bdf-1814-4522-ad3e-d33f618c7b70",
   "metadata": {},
   "source": [
    "First dry run the model using the above specification and get an idea of the cost required to run the model \n",
    "\n",
    "Running it on just 100 examples to get an idea for the notebook, adjust the max_items as required and dont pass it if you need to run the oracle on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config=zero_shot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f2ded15aca4c5c8f283d3592821eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.023\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.00231\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at identifying toxic comments and understanding if a comment is sexually explicit, obscene, toxic, insults a person, demographic or race.\n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent.plan('../data/civil_comments_test.csv', max_items=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2d4846d-d16b-40e9-b2cb-a0c579e260e4",
   "metadata": {},
   "source": [
    "Now, actually run the model and generate the list of labels for the banking dataset. You will get the computed metrics at the end of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f2604a3a2941f0bb856c5ddc104e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 0.029609999999999997\n",
      "Metric: support: [(100, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.69, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/civil_comments_test.csv', max_items = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8973f5c-7aa2-443f-81f8-9046ed8c2046",
   "metadata": {},
   "source": [
    "## Change the prompt\n",
    "Analyze the dataframe generated above and make changes to the prompt in order to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a1a4042-4aee-481f-ac77-b21d14925cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fixed_few_shot = {\n",
    "    \"task_name\": \"ToxicCommentClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\",\n",
    "        \"compute_confidence\": True\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
    "        \"labels\": [\n",
    "            \"toxic\",\n",
    "            \"not toxic\"\n",
    "        ],\n",
    "        \"few_shot_examples\": [\n",
    "            {\n",
    "                \"example\": \"It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
    "                \"label\": \"not toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This bitch is nuts. Who would read a book by a woman\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"It was a great show. Not a combo I'd of expected to be good together but it was.\",\n",
    "                \"label\": \"not toxic\"\n",
    "            }\n",
    "        ],\n",
    "        \"few_shot_selection\": \"fixed\",\n",
    "        \"few_shot_num\": 4,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84eecfba-9859-4d6c-9f44-3755c71d3ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d86ebbf09ad47c9916b236826ce1295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> $1.334  </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 500     </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 0.00267 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mTotal Estimated Cost    \u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m$1.334 \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mNumber of Examples      \u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m500    \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mAverage cost per example\u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m0.00267\u001b[0m\u001b[1;35m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\n",
      "Output: toxic\n",
      "\n",
      "Input: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "Output: not toxic\n",
      "\n",
      "Input: This bitch is nuts. Who would read a book by a woman\n",
      "Output: toxic\n",
      "\n",
      "Input: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = LabelingAgent(config_fixed_few_shot)\n",
    "agent.plan('../data/civil_comments_test.csv', max_items = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a586b441-9e5c-459c-8c65-4f8294dac189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc444e1061b47628310f26e5c832228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.9146988181018286\n",
      "Metric: support: [500, 0, 1, 65, 66, 71, 72, 127, 128, 162, 163, 223, 224, 244, 245, 252, 253, 254, 255, 264, 265, 268, 269, 280, 281, 282, 283, 303, 304, 305, 306, 315, 316, 321, 322, 335, 336, 338, 339, 344, 345, 364, 365, 366, 367, 368, 370, 376, 377, 381, 382, 383, 386, 388, 389, 402, 403, 405, 406, 407, 408, 410, 413, 416, 418, 419, 421, 422, 424, 425, 426, 428, 430, 431, 436, 437, 447, 448, 451, 452, 458, 459, 460, 462, 500]\n",
      "Metric: threshold: [-inf, 3.714736099352354, 2.714736099352354, 2.6956947829795728, 2.6953603567774245, 2.6932779353180107, 2.6930515146268585, 2.6764719328942537, 2.676189180624304, 2.6612719917617036, 2.6612342394766104, 2.625178818845078, 2.6251451773976777, 2.608572137984105, 2.60735669953346, 2.601123030085829, 2.6007889424670774, 2.6004625702297046, 2.600152356939121, 2.5931752615876684, 2.59188025063899, 2.5900612511258525, 2.5890796595963828, 2.5726048870966935, 2.571877012231934, 2.5711248996584968, 2.5681220157605713, 2.5462137356358974, 2.545782680334916, 2.5434239817362245, 2.542894877386798, 2.5278687800646336, 2.5278446725442794, 2.5163890293059628, 2.5090863581731155, 2.4572194048158633, 2.4416253770979686, 2.4356603245282575, 2.430112483473423, 2.4031084946265864, 2.4019907943098664, 2.331858156919807, 2.3208982578865562, 2.3115760088869783, 2.2988888381566084, 2.2956292840818913, 2.288206370166174, 2.2467403415555562, 2.236254744251851, 2.2117215131728503, 2.205834764903732, 2.2052090184071824, 2.18709857954395, 2.1710329088899267, 2.1690239415443795, 2.0353950890607715, 2.0291283479858033, 2.024946528536721, 2.0216032001728355, 2.0051229867799774, 2.0047768126228624, 2.0043981121314873, 1.9904700639051627, 1.9773344817560619, 1.9590580572331886, 1.9557275172277595, 1.9428738416950033, 1.9381831853298919, 1.9017194373284678, 1.8992638793223553, 1.8914559823905228, 1.881635595845531, 1.8626513555478963, 1.859474212404391, 1.8059090530372626, 1.7882882379414422, 1.6756058363807707, 1.6733277009139507, 1.559468219477614, 1.5570788267640299, 1.4586172258491115, 1.4567792049991326, 1.4175798285915766, 1.3941340687342754, 1.015056761730656]\n",
      "Metric: accuracy: [0.786, 0.0, 1.0, 1.0, 0.9848484848484849, 0.9859154929577465, 0.9722222222222222, 0.984251968503937, 0.9765625, 0.9814814814814815, 0.9754601226993865, 0.9820627802690582, 0.9776785714285714, 0.9795081967213115, 0.9755102040816327, 0.9761904761904762, 0.9723320158102767, 0.9724409448818898, 0.9686274509803922, 0.9696969696969697, 0.9660377358490566, 0.9664179104477612, 0.9628252788104089, 0.9642857142857143, 0.9608540925266904, 0.9609929078014184, 0.9575971731448764, 0.9603960396039604, 0.9572368421052632, 0.9573770491803278, 0.954248366013072, 0.9555555555555556, 0.9525316455696202, 0.9532710280373832, 0.9503105590062112, 0.9522388059701492, 0.9494047619047619, 0.9497041420118343, 0.9469026548672567, 0.9476744186046512, 0.9449275362318841, 0.9478021978021978, 0.9452054794520548, 0.9453551912568307, 0.9427792915531336, 0.9429347826086957, 0.9378378378378378, 0.9388297872340425, 0.9363395225464191, 0.937007874015748, 0.9345549738219895, 0.9347258485639687, 0.927461139896373, 0.9278350515463918, 0.9254498714652957, 0.927860696517413, 0.9255583126550868, 0.9259259259259259, 0.9236453201970444, 0.9238329238329238, 0.9215686274509803, 0.9219512195121952, 0.9152542372881356, 0.9158653846153846, 0.9114832535885168, 0.9116945107398569, 0.9073634204275535, 0.9075829383886256, 0.9033018867924528, 0.9035294117647059, 0.9014084507042254, 0.9018691588785047, 0.8976744186046511, 0.8979118329466357, 0.8876146788990825, 0.8878718535469108, 0.8680089485458613, 0.8683035714285714, 0.8625277161862528, 0.8628318584070797, 0.851528384279476, 0.8518518518518519, 0.85, 0.8506493506493507, 0.786]\n",
      "Metric: completion_rate: [1.0, 0.0, 0.002, 0.13, 0.132, 0.142, 0.144, 0.254, 0.256, 0.324, 0.326, 0.446, 0.448, 0.488, 0.49, 0.504, 0.506, 0.508, 0.51, 0.528, 0.53, 0.536, 0.538, 0.56, 0.562, 0.564, 0.566, 0.606, 0.608, 0.61, 0.612, 0.63, 0.632, 0.642, 0.644, 0.67, 0.672, 0.676, 0.678, 0.688, 0.69, 0.728, 0.73, 0.732, 0.734, 0.736, 0.74, 0.752, 0.754, 0.762, 0.764, 0.766, 0.772, 0.776, 0.778, 0.804, 0.806, 0.81, 0.812, 0.814, 0.816, 0.82, 0.826, 0.832, 0.836, 0.838, 0.842, 0.844, 0.848, 0.85, 0.852, 0.856, 0.86, 0.862, 0.872, 0.874, 0.894, 0.896, 0.902, 0.904, 0.916, 0.918, 0.92, 0.924, 1.0]\n",
      "Actual Cost: 0.002944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of failures: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of failures: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/civil_comments_test.csv', max_items=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3806642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auroc'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a009109-e72b-4b69-9bc8-ea23af9a53e3",
   "metadata": {},
   "source": [
    "## Example selector\n",
    "Let's try to use an example selector. Let's use the big seed example set so that we can choose from a bigger set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "517c7fa8-8926-42b5-b8d8-3aa73e5f64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_similarity_few_shot = {\n",
    "    \"task_name\": \"ToxicCommentClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"name\": \"gpt-3.5-turbo\"\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
    "        \"labels\": [\n",
    "            \"toxic\",\n",
    "            \"not toxic\"\n",
    "        ],\n",
    "        \"few_shot_examples\": \"../data/civil_comments_seed_v2.csv\",\n",
    "        \"few_shot_selection\": \"semantic_similarity\",\n",
    "        \"few_shot_num\": 3,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a53186c-4fd2-46c2-b283-944b1ca9c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_similarity_few_shot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45e87c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062a75e9f30b4a98857da97293e72ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.282\n",
      "Number of examples to label: 100\n",
      "Average cost per example: $0.00282\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: If Trump wants to totally reinvent the world political and economic order, I think he owes the American public some specific plans and proposed policies. Having \"lots of meetings\", and telling everyone what a great negotiator he is, is not a plan. The USA is already a great nation with great influence in the world, and we need to honor our long term alliances and commitments, or risk losing much financial and political power and influence. For Pete's sake, we owe these countries trillions of dollars of our national debit. What happens if they ask for their money back? But then Trump is unquestionably experienced in bankruptcies.\n",
      "Output: not toxic\n",
      "\n",
      "Input: Are you talking about the crooked Trump Foundation?\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]. . Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/civil_comments_test_v2.csv', max_items=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca976604-a13c-42a7-a380-7a27d3d3b8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb410807864b4bb383704eab8e78839b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 0.03514199999999999\n",
      "Metric: support: [(100, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.68, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run(\n",
    "    '../data/civil_comments_test_v2.csv', max_items=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea85e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Davinci\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "config_v4 = deepcopy(config_fixed_few_shot)\n",
    "\n",
    "config_v4['model'] = {'provider': 'openai', 'name': 'text-davinci-003'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f745f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486b4232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47a9cb8e1c54df981ef36d155f70cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $13.489\n",
      "Number of examples to label: 500\n",
      "Average cost per example: $0.02698\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\n",
      "Output: toxic\n",
      "\n",
      "Input: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "Output: not toxic\n",
      "\n",
      "Input: This bitch is nuts. Who would read a book by a woman\n",
      "Output: toxic\n",
      "\n",
      "Input: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/civil_comments_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd143f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4925f3f8a95741fcb2ccca450486bc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 3.5054600000000016\n",
      "Metric: support: [(500, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.876, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/civil_comments_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "866f8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_v5 = {\n",
    "    \"task_name\": \"ToxicCommentClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\"provider\": \"anthropic\", \"name\": \"claude-v1\"},\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy, politicians and companies are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or has a slur against a person, gender or race are not allowed and labeled 'toxic'.\\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
    "        \"labels\": [\n",
    "            \"toxic\",\n",
    "            \"not toxic\"\n",
    "        ],\n",
    "        \"few_shot_examples\": [\n",
    "            {\n",
    "                \"example\": \"It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
    "                \"label\": \"not toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This bitch is nuts. Who would read a book by a woman\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"It was a great show. Not a combo I'd of expected to be good together but it was.\",\n",
    "                \"label\": \"not toxic\"\n",
    "            }\n",
    "        ],\n",
    "        \"few_shot_selection\": \"fixed\",\n",
    "        \"few_shot_num\": 4,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e663c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f75d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b82bb4ec4d24d25828b9f4a08b7aeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.367\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.03669\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy, politicians and companies are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or has a slur against a person, gender or race are not allowed and labeled 'toxic'.\n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\n",
      "Output: toxic\n",
      "\n",
      "Input: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "Output: not toxic\n",
      "\n",
      "Input: This bitch is nuts. Who would read a book by a woman\n",
      "Output: toxic\n",
      "\n",
      "Input: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/civil_comments_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3be6bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee2fe8b85e342fda1ea44c42b115bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 1.9847244199999996\n",
      "Metric: support: [(500, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.854, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run(\n",
    "    '../data/civil_comments_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "232114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_v6 = {\n",
    "    \"task_name\": \"ToxicCommentClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": \"label\",\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\"provider\": \"openai\", \"name\": \"gpt-4\"},\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": \"You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy, politicians and companies are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or has a slur against a person, gender or race are not allowed and labeled 'toxic'.\\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
    "        \"labels\": [\n",
    "            \"toxic\",\n",
    "            \"not toxic\"\n",
    "        ],\n",
    "        \"few_shot_examples\": [\n",
    "            {\n",
    "                \"example\": \"It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
    "                \"label\": \"not toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"This bitch is nuts. Who would read a book by a woman\",\n",
    "                \"label\": \"toxic\"\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"It was a great show. Not a combo I'd of expected to be good together but it was.\",\n",
    "                \"label\": \"not toxic\"\n",
    "            }\n",
    "        ],\n",
    "        \"few_shot_selection\": \"fixed\",\n",
    "        \"few_shot_num\": 4,\n",
    "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28b56cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autolabel.models.openai.OpenAILLM at 0x289410f70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = LabelingAgent(config_v6)\n",
    "agent.llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11b77062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629301a42977400fa4f42b34e3dac97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Estimated Cost: $0.704\n",
      "Number of examples to label: 10\n",
      "Average cost per example: $0.0704\n",
      "\n",
      "\n",
      "A prompt example:\n",
      "\n",
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy, politicians and companies are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or has a slur against a person, gender or race are not allowed and labeled 'toxic'.\n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\n",
      "Output: toxic\n",
      "\n",
      "Input: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "Output: not toxic\n",
      "\n",
      "Input: This bitch is nuts. Who would read a book by a woman\n",
      "Output: toxic\n",
      "\n",
      "Input: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "agent.plan('../data/civil_comments_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6fef630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf0ab4b2713460092cf1b7bef17dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:30:58 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 16:30:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d0093279d47984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:37:58 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-31 09:37:58 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 16:37:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d009d6b5cd9984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:43:49 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-31 09:43:49 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 16:43:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d00a5fcdc1f984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:51:22 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-31 09:51:22 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 16:51:22 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d00b109cfb2984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:59:13 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-31 09:59:13 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 16:59:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d00bc766c70984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 10:06:32 openai INFO: error_code=502 error_message='Bad gateway.' error_param=None error_type=cf_bad_gateway message='OpenAI API error received' stream_error=False\n",
      "2023-05-31 10:06:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 31 May 2023 17:06:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d00c740c9ae984f-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 10:09:11 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: Actual Cost: 5.105519999999998\n",
      "Metric: support: [(500, 'index=0')]\n",
      "Metric: threshold: [(-inf, 'index=0')]\n",
      "Metric: accuracy: [(0.876, 'index=0')]\n",
      "Metric: completion_rate: [(1.0, 'index=0')]\n",
      "Total number of failures: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0      not toxic\n",
       " 1      not toxic\n",
       " 2      not toxic\n",
       " 3      not toxic\n",
       " 4      not toxic\n",
       "          ...    \n",
       " 495    not toxic\n",
       " 496    not toxic\n",
       " 497    not toxic\n",
       " 498    not toxic\n",
       " 499    not toxic\n",
       " Name: ToxicCommentClassification_llm_label, Length: 500, dtype: object,\n",
       "                                                example      label  \\\n",
       " 0    [ Integrity means that you pay your debts.]\\n\\...  not toxic   \n",
       " 1    This is malfeasance by the Administrator and t...  not toxic   \n",
       " 2    @Rmiller101 - Spoken like a true elitist. But ...  not toxic   \n",
       " 3    Paul: Thank you for your kind words.  I do, in...  not toxic   \n",
       " 4    Sorry you missed high school. Eisenhower sent ...  not toxic   \n",
       " ..                                                 ...        ...   \n",
       " 495       No surprise.  Deep ecology is based on lies.  not toxic   \n",
       " 496  In a \"huff\" with 2000 years of magisterial tea...  not toxic   \n",
       " 497  Unreasonable petulance is not going to serve M...  not toxic   \n",
       " 498  The US should pull its nukes out of every coun...  not toxic   \n",
       " 499  No, it was a rhetorical statement on the lines...  not toxic   \n",
       " \n",
       "     ToxicCommentClassification_llm_labeled_successfully  \\\n",
       " 0                                                  yes    \n",
       " 1                                                  yes    \n",
       " 2                                                  yes    \n",
       " 3                                                  yes    \n",
       " 4                                                  yes    \n",
       " ..                                                 ...    \n",
       " 495                                                yes    \n",
       " 496                                                yes    \n",
       " 497                                                yes    \n",
       " 498                                                yes    \n",
       " 499                                                yes    \n",
       " \n",
       "     ToxicCommentClassification_llm_label  \n",
       " 0                              not toxic  \n",
       " 1                              not toxic  \n",
       " 2                              not toxic  \n",
       " 3                              not toxic  \n",
       " 4                              not toxic  \n",
       " ..                                   ...  \n",
       " 495                            not toxic  \n",
       " 496                            not toxic  \n",
       " 497                            not toxic  \n",
       " 498                            not toxic  \n",
       " 499                            not toxic  \n",
       " \n",
       " [500 rows x 4 columns],\n",
       " [MetricResult(metric_type=<Metric.SUPPORT: 'support'>, name='support', value=[(500, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.THRESHOLD: 'threshold'>, name='threshold', value=[(-inf, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.ACCURACY: 'accuracy'>, name='accuracy', value=[(0.876, 'index=0')]),\n",
       "  MetricResult(metric_type=<Metric.COMPLETION_RATE: 'completion_rate'>, name='completion_rate', value=[(1.0, 'index=0')])])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('../data/civil_comments_test.csv', max_items=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b9cae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "config_refuel = deepcopy(config_fixed_few_shot)\n",
    "\n",
    "config_refuel['model'] = {'provider': 'refuel', 'name': 'flan-t5-xxl', 'compute_confidence': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f187723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autolabel.models.refuel.RefuelLLM at 0x17675fdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = LabelingAgent(config_refuel)\n",
    "agent.llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56118b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'ToxicCommentClassification',\n",
       " 'task_type': 'classification',\n",
       " 'dataset': {'label_column': 'label', 'delimiter': ','},\n",
       " 'model': {'provider': 'refuel',\n",
       "  'name': 'flan-t5-xxl',\n",
       "  'compute_confidence': True},\n",
       " 'prompt': {'task_guidelines': \"You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \\nYour job is to correctly label the provided input example into one of the following categories:\\n{labels}\",\n",
       "  'labels': ['toxic', 'not toxic'],\n",
       "  'few_shot_examples': [{'example': \"It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\",\n",
       "    'label': 'toxic'},\n",
       "   {'example': \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
       "    'label': 'not toxic'},\n",
       "   {'example': 'This bitch is nuts. Who would read a book by a woman',\n",
       "    'label': 'toxic'},\n",
       "   {'example': \"It was a great show. Not a combo I'd of expected to be good together but it was.\",\n",
       "    'label': 'not toxic'}],\n",
       "  'few_shot_selection': 'fixed',\n",
       "  'few_shot_num': 4,\n",
       "  'example_template': 'Input: {example}\\nOutput: {label}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_refuel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722863b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447b60aa227f4be6926dcc22f9e2f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬──────┐\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> $0.0 </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 10   </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 0.0  </span>│\n",
       "└──────────────────────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬──────┐\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mTotal Estimated Cost    \u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m$0.0\u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mNumber of Examples      \u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m10  \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "│\u001b[1;32m \u001b[0m\u001b[1;32mAverage cost per example\u001b[0m\u001b[1;32m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m0.0 \u001b[0m\u001b[1;35m \u001b[0m│\n",
       "└──────────────────────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at identifying toxic comments. You aim to act in a fair and balanced manner, where comments that provide fair criticism of something or someone are labelled 'not toxic'. Similarly, criticisms of policy and politicians are marked 'not toxic', unless the comment includes obscenities, racial slurs or sexually explicit material. Any comments that are sexually explicit, obscene, or insults a person, demographic or race are not allowed and labeled 'toxic'. \n",
      "Your job is to correctly label the provided input example into one of the following categories:\n",
      "toxic\n",
      "not toxic\n",
      "\n",
      "You will return the answer with just one element: \"the correct label\"\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.\n",
      "Output: toxic\n",
      "\n",
      "Input: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "Output: not toxic\n",
      "\n",
      "Input: This bitch is nuts. Who would read a book by a woman\n",
      "Output: toxic\n",
      "\n",
      "Input: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "Output: not toxic\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: [ Integrity means that you pay your debts.]\n",
      "\n",
      "Does this apply to President Trump too?\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.plan('../data/civil_comments_test.csv', max_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e65d6238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c209bc3054ac445d9cdabbc3231cee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.8782007575757576\n",
      "Metric: support: [1000, 0, 1, 142, 143, 161, 162, 282, 283, 359, 360, 475, 476, 499, 500, 505, 506, 517, 518, 532, 533, 534, 535, 550, 551, 557, 558, 590, 591, 593, 595, 618, 619, 623, 624, 634, 635, 637, 638, 650, 651, 669, 671, 682, 684, 688, 689, 703, 704, 712, 713, 714, 715, 716, 717, 726, 727, 736, 737, 741, 742, 746, 748, 750, 751, 759, 760, 765, 766, 779, 781, 801, 802, 832, 833, 836, 837, 844, 845, 847, 849, 850, 851, 868, 869, 870, 872, 878, 880, 883, 884, 885, 886, 887, 888, 890, 893, 897, 898, 900, 901, 909, 910, 913, 914, 919, 920, 923, 925, 926, 927, 929, 931, 933, 937, 939, 941, 942, 943, 944, 945, 946, 947, 949, 958, 961, 962, 963, 969, 970, 986, 987, 991, 992, 1000]\n",
      "Metric: threshold: [-inf, 3.714894193186108, 2.714894193186108, 2.695390078300664, 2.6953603567774245, 2.6932779353180107, 2.6930515146268585, 2.6762328876269037, 2.676189180624304, 2.6612719917617036, 2.6612342394766104, 2.625178818845078, 2.6251451773976777, 2.6164023299668755, 2.615370925840028, 2.6135681541718814, 2.6134834886776885, 2.6084142497601253, 2.60735669953346, 2.600824984657809, 2.6007889424670774, 2.6004625702297046, 2.600152356939121, 2.5918807913474025, 2.59188025063899, 2.5900612511258525, 2.5890796595963828, 2.5721602418457534, 2.571877012231934, 2.5699664300147327, 2.5681220157605713, 2.555510256181596, 2.554325935870228, 2.550365873203096, 2.550285383244569, 2.5462137356358974, 2.545782680334916, 2.5434239817362245, 2.542894877386798, 2.5278687800646336, 2.5278446725442794, 2.5110533046787267, 2.5079512818709877, 2.501587100612189, 2.497166731194651, 2.4934099412612514, 2.4919296915791125, 2.476748913763128, 2.4761717643789907, 2.469967357178705, 2.468818339670471, 2.468448718905382, 2.4667454561627666, 2.4663637236405234, 2.466076268725651, 2.450882065174299, 2.4496769497994677, 2.4423439025724916, 2.4416253770979686, 2.4337823901818885, 2.430112483473423, 2.425917530062413, 2.4238076363972962, 2.420981209375944, 2.4207966545044775, 2.410929728579574, 2.4084926153135635, 2.402908330054925, 2.4019907943098664, 2.3834799787212386, 2.3800867944178576, 2.354857347714684, 2.354173119834356, 2.325561411679195, 2.3208982578865562, 2.3169381664417052, 2.315909064644692, 2.30353090570173, 2.2988888381566084, 2.2956292840818913, 2.288206370166174, 2.287911109786551, 2.2858564577873097, 2.254172096803646, 2.2469109572212274, 2.2467403415555562, 2.236254744251851, 2.218220384870706, 2.217155902999565, 2.2059459980941702, 2.205834764903732, 2.2052090184071824, 2.2002654968014266, 2.1993165320137127, 2.193186498219259, 2.190938999940931, 2.1869972260330868, 2.1745843172119255, 2.1712068990626308, 2.1710329088899267, 2.1690239415443795, 2.142700906628349, 2.1422070899203414, 2.1398409170987853, 2.135131235404851, 2.1207496445524723, 2.106590356969504, 2.0815848713427845, 2.0772165392604407, 2.070076728155715, 2.066572075653821, 2.0631729943892996, 2.0461047278655498, 2.045542094043666, 2.0291283479858033, 2.024946528536721, 2.0216032001728355, 2.0161865410384, 2.0047768126228624, 2.0043981121314873, 1.9967877500915499, 1.9963072139469669, 1.9904700639051627, 1.9887268011917683, 1.9236912250510627, 1.8995361567392726, 1.8992660302176017, 1.8870790649339853, 1.8379896273018033, 1.8317553905245478, 1.7379955521302854, 1.732826111169882, 1.6323566128779357, 1.6207525945854608, 1.417852433547294]\n",
      "Metric: accuracy: [0.88, 0.0, 1.0, 1.0, 0.993006993006993, 0.9937888198757764, 0.9876543209876543, 0.9929078014184397, 0.9893992932862191, 0.9916434540389972, 0.9888888888888889, 0.991578947368421, 0.9894957983193278, 0.9899799599198397, 0.988, 0.9881188118811881, 0.9861660079051383, 0.9864603481624759, 0.9845559845559846, 0.9849624060150376, 0.9831144465290806, 0.9831460674157303, 0.9813084112149533, 0.9818181818181818, 0.9800362976406534, 0.9802513464991023, 0.978494623655914, 0.9796610169491525, 0.9780033840947546, 0.9780775716694773, 0.9747899159663865, 0.9757281553398058, 0.9741518578352181, 0.9743178170144462, 0.9727564102564102, 0.973186119873817, 0.9716535433070866, 0.9717425431711146, 0.9702194357366771, 0.9707692307692307, 0.9692780337941628, 0.9701046337817638, 0.9672131147540983, 0.967741935483871, 0.9649122807017544, 0.9651162790697675, 0.9637155297532656, 0.9644381223328592, 0.9630681818181818, 0.9634831460674157, 0.9621318373071529, 0.9621848739495799, 0.9608391608391609, 0.9608938547486033, 0.9595536959553695, 0.9600550964187328, 0.9587345254470426, 0.9592391304347826, 0.9579375848032564, 0.9581646423751687, 0.9568733153638814, 0.9571045576407506, 0.9545454545454546, 0.9546666666666667, 0.9533954727030626, 0.9538866930171278, 0.9526315789473684, 0.9529411764705882, 0.9516971279373369, 0.9525032092426188, 0.9500640204865557, 0.951310861423221, 0.9501246882793017, 0.9519230769230769, 0.9507803121248499, 0.9509569377990431, 0.9498207885304659, 0.9502369668246445, 0.9491124260355029, 0.9492325855962219, 0.9469964664310954, 0.9470588235294117, 0.9459459459459459, 0.9470046082949308, 0.9459148446490219, 0.9459770114942528, 0.9438073394495413, 0.9441913439635535, 0.9420454545454545, 0.942242355605889, 0.9411764705882353, 0.9412429378531073, 0.9401805869074492, 0.9402480270574972, 0.9391891891891891, 0.9393258426966292, 0.9361702127659575, 0.9364548494983278, 0.9354120267260579, 0.9355555555555556, 0.9345172031076582, 0.935093509350935, 0.9340659340659341, 0.9342825848849945, 0.9332603938730853, 0.9336235038084875, 0.9326086956521739, 0.9328277356446371, 0.9308108108108109, 0.9308855291576674, 0.9298813376483279, 0.930032292787944, 0.9280343716433942, 0.9281886387995713, 0.9242262540021344, 0.9243876464323749, 0.922422954303932, 0.9225053078556263, 0.9215270413573701, 0.9216101694915254, 0.9206349206349206, 0.9207188160676533, 0.9197465681098205, 0.9199157007376185, 0.9112734864300627, 0.9115504682622269, 0.9106029106029107, 0.9106957424714434, 0.9050567595459237, 0.9051546391752577, 0.8904665314401623, 0.8905775075987842, 0.8869828456104945, 0.8870967741935484, 0.88]\n",
      "Metric: completion_rate: [1.0, 0.0, 0.001, 0.142, 0.143, 0.161, 0.162, 0.282, 0.283, 0.359, 0.36, 0.475, 0.476, 0.499, 0.5, 0.505, 0.506, 0.517, 0.518, 0.532, 0.533, 0.534, 0.535, 0.55, 0.551, 0.557, 0.558, 0.59, 0.591, 0.593, 0.595, 0.618, 0.619, 0.623, 0.624, 0.634, 0.635, 0.637, 0.638, 0.65, 0.651, 0.669, 0.671, 0.682, 0.684, 0.688, 0.689, 0.703, 0.704, 0.712, 0.713, 0.714, 0.715, 0.716, 0.717, 0.726, 0.727, 0.736, 0.737, 0.741, 0.742, 0.746, 0.748, 0.75, 0.751, 0.759, 0.76, 0.765, 0.766, 0.779, 0.781, 0.801, 0.802, 0.832, 0.833, 0.836, 0.837, 0.844, 0.845, 0.847, 0.849, 0.85, 0.851, 0.868, 0.869, 0.87, 0.872, 0.878, 0.88, 0.883, 0.884, 0.885, 0.886, 0.887, 0.888, 0.89, 0.893, 0.897, 0.898, 0.9, 0.901, 0.909, 0.91, 0.913, 0.914, 0.919, 0.92, 0.923, 0.925, 0.926, 0.927, 0.929, 0.931, 0.933, 0.937, 0.939, 0.941, 0.942, 0.943, 0.944, 0.945, 0.946, 0.947, 0.949, 0.958, 0.961, 0.962, 0.963, 0.969, 0.97, 0.986, 0.987, 0.991, 0.992, 1.0]\n",
      "Actual Cost: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of failures: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of failures: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, df, metrics_list = agent.run('../data/civil_comments_test.csv', max_items=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6303044-13a9-4a00-a1e5-45f89c667691",
   "metadata": {},
   "source": [
    "## Confidence estimation\n",
    "Let's try to see if the model is able to do well on confidence estimation, if the model knows what it doesn't know we might be able to trade off completion rate for accuracy and get a higher accuracy even though we may be labeling less amount of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9435243-5df4-4654-a770-6c832d2ee916",
   "metadata": {},
   "source": [
    "## Chain of thought reasoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1060411-126c-4c3f-8bc3-452babc0fe20",
   "metadata": {},
   "source": [
    "Chain of thought requires an explanation for every seed example. As we don't have the explanations or the domain knowledge to construct these explanations, we can use the model to generate the explanations and then use these explanations as an input to the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08355115-45fc-4719-9111-44883085ada2",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "I am noting a few things that I did not try out, but would have wanted to try to boost completion rate while keeping the accuracy high\n",
    "\n",
    "1. Wanted to try chain of thought reasoning with a semantic similarity example selector\n",
    "2. Increase the number of seed examples to be close to one example per class\n",
    "3. Find the annotator guidelines and pass these as part of the prompt to the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3dcb74e-2b04-4e73-b303-575e29f52f3c",
   "metadata": {},
   "source": [
    "Trying out all bells and whistles together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66e52a-2925-477b-9b21-0558201e233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"labels_list\": [\n",
    "        \"activate_my_card\",\n",
    "        \"age_limit\",\n",
    "        \"apple_pay_or_google_pay\",\n",
    "        \"atm_support\",\n",
    "        \"automatic_top_up\",\n",
    "        \"balance_not_updated_after_bank_transfer\",\n",
    "        \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "        \"beneficiary_not_allowed\",\n",
    "        \"cancel_transfer\",\n",
    "        \"card_about_to_expire\",\n",
    "        \"card_acceptance\",\n",
    "        \"card_arrival\",\n",
    "        \"card_delivery_estimate\",\n",
    "        \"card_linking\",\n",
    "        \"card_not_working\",\n",
    "        \"card_payment_fee_charged\",\n",
    "        \"card_payment_not_recognised\",\n",
    "        \"card_payment_wrong_exchange_rate\",\n",
    "        \"card_swallowed\",\n",
    "        \"cash_withdrawal_charge\",\n",
    "        \"cash_withdrawal_not_recognised\",\n",
    "        \"change_pin\",\n",
    "        \"compromised_card\",\n",
    "        \"contactless_not_working\",\n",
    "        \"country_support\",\n",
    "        \"declined_card_payment\",\n",
    "        \"declined_cash_withdrawal\",\n",
    "        \"declined_transfer\",\n",
    "        \"direct_debit_payment_not_recognised\",\n",
    "        \"disposable_card_limits\",\n",
    "        \"edit_personal_details\",\n",
    "        \"exchange_charge\",\n",
    "        \"exchange_rate\",\n",
    "        \"exchange_via_app\",\n",
    "        \"extra_charge_on_statement\",\n",
    "        \"failed_transfer\",\n",
    "        \"fiat_currency_support\",\n",
    "        \"get_disposable_virtual_card\",\n",
    "        \"get_physical_card\",\n",
    "        \"getting_spare_card\",\n",
    "        \"getting_virtual_card\",\n",
    "        \"lost_or_stolen_card\",\n",
    "        \"lost_or_stolen_phone\",\n",
    "        \"order_physical_card\",\n",
    "        \"passcode_forgotten\",\n",
    "        \"pending_card_payment\",\n",
    "        \"pending_cash_withdrawal\",\n",
    "        \"pending_top_up\",\n",
    "        \"pending_transfer\",\n",
    "        \"pin_blocked\",\n",
    "        \"receiving_money\",\n",
    "        \"Refund_not_showing_up\",\n",
    "        \"request_refund\",\n",
    "        \"reverted_card_payment?\",\n",
    "        \"supported_cards_and_currencies\",\n",
    "        \"terminate_account\",\n",
    "        \"top_up_by_bank_transfer_charge\",\n",
    "        \"top_up_by_card_charge\",\n",
    "        \"top_up_by_cash_or_cheque\",\n",
    "        \"top_up_failed\",\n",
    "        \"top_up_limits\",\n",
    "        \"top_up_reverted\",\n",
    "        \"topping_up_by_card\",\n",
    "        \"transaction_charged_twice\",\n",
    "        \"transfer_fee_charged\",\n",
    "        \"transfer_into_account\",\n",
    "        \"transfer_not_received_by_recipient\",\n",
    "        \"transfer_timing\",\n",
    "        \"unable_to_verify_identity\",\n",
    "        \"verify_my_identity\",\n",
    "        \"verify_source_of_funds\",\n",
    "        \"verify_top_up\",\n",
    "        \"virtual_card_not_working\",\n",
    "        \"visa_or_mastercard\",\n",
    "        \"why_verify_identity\",\n",
    "        \"wrong_amount_of_cash_received\",\n",
    "        \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "    ],\n",
    "    \"dataset_schema\": {\n",
    "        \"input_columns\": [\n",
    "            \"example\"\n",
    "        ],\n",
    "        \"label_column\": \"label\"\n",
    "    },\n",
    "    \"seed_examples\": 'data/banking_seed.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec89ad-ae8a-4240-bfc2-3a2521a07d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = {\n",
    "    \"project_name\": \"BankingClassification\",\n",
    "    \"task_type\": \"classification\",\n",
    "    \"prefix_prompt\": \"You are an expert at understanding twitter complaints.\",\n",
    "    \"example_selector\": {\n",
    "        \"strategy\": \"semantic_similarity\",\n",
    "        \"num_examples\": 4\n",
    "    },\n",
    "    \"compute_confidence\": \"True\",\n",
    "    \"chain_of_thought\": \"True\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb13fdab-dba7-4fa4-847a-3084e6673cae",
   "metadata": {},
   "source": [
    "Increase the maximum tokens allowed on the llm in case of chain of thought because some times the number of tokens produced by the llm in the explanation would exceed the default max token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a99f6-d1ee-4c45-a2f8-cc6f22c3516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"provider_name\": \"openai\",\n",
    "    \"model_name\": \"gpt-3.5-turbo\",\n",
    "    \"has_logprob\": False,\n",
    "    \"model_params\": {\n",
    "        \"max_tokens\": 1000, # This increases the maximum tokens\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8b4a6-e379-4912-84f6-c7d63b472ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = LabelingAgent(task_config, llm_config)\n",
    "o.plan('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac410611-2b8a-4728-9324-5555ecc65f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, df, metrics_list = o.run('data/banking_test.csv', dataset_config, max_items = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c04ce7f5-bf94-4fb2-8655-0430513d58f7",
   "metadata": {},
   "source": [
    "Increase the maximum tokens allowed on the llm in case of chain of thought because some times the number of tokens produced by the llm in the explanation would exceed the default max token limit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d71cd57f-cffb-47d7-83d2-0f272d65929e",
   "metadata": {},
   "source": [
    "## Self consistency\n",
    "\n",
    "This increases the temperature and the randomness while generating explanations allowing the model to explore multiple reasoning paths. At the end, a majority vote is taken among the generations. The llm config below generates 5 reasoning paths and takes the majority vote over these reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d780e-44ab-482f-8cdf-9e9b932226cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"provider_name\": \"openai\",\n",
    "    \"model_name\": \"gpt-3.5-turbo\",\n",
    "    \"has_logprob\": False,\n",
    "    \"model_params\": {\n",
    "        \"max_tokens\": 1000, # This increases the maximum tokens\n",
    "        \"temperature\": 0.7,\n",
    "        \"n\": 5 # This runs self consistency\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c95fb-6a14-4df8-9090-bead4073dae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
