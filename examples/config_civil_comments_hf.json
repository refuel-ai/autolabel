{
    "project_name": "Toxic Comment Classification",
    "task_type": "classification",
    "provider_name": "huggingface",
    "model_name": "flan-t5-xxl",
    "quantize": 16,
    "output_format": "csv",
    "model_params": {},
    "prefix_prompt": "You are an expert at identifying toxic comments and understanding if a comment is sexually explicit, obscene, toxic, insults a person, demographic or race.",
    "labels_list": [
        "toxic",
        "not toxic"
    ],
    "dataset_schema": {
        "input_columns": [
            "text"
        ],
        "label_column": "label"
    },
    "seed_examples": [
        {
            "example": "It's ridiculous that these guys are being called 'protesters'. Being armed is a threat of violence, which makes them terrorists.",
            "label": "toxic"
        },
        {
            "example": "This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!",
            "output": "not toxic"
        },
        {
            "example": "This bitch is nuts. Who would read a book by a woman",
            "output": "toxic"
        },
        {
            "example": "It was a great show. Not a combo I'd of expected to be good together but it was.",
            "output": "not toxic"
        }
    ]
}